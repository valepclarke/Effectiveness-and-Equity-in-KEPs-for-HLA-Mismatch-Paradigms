{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import networkx as nx\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "#Compatibility\n",
    "compatibility = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/compatibilidad_total.csv', index_col=0)\n",
    "compatibility.index = range(len(compatibility))\n",
    "compatibility.columns = range(len(compatibility.columns))\n",
    "#Pairs, recipients and donors\n",
    "pairs = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/parejas.csv',index_col=0)\n",
    "recipients = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/receptores.csv',index_col=0)\n",
    "donors = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/donantes.csv',index_col=0)\n",
    "#Weights\n",
    "hla_hr = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_ar.csv\",index_col=0)\n",
    "hla_lr = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_BR.csv\",index_col=0)\n",
    "hla_eplet = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_eplet.csv\",index_col=0)\n",
    "hla_hr.columns = hla_hr.columns.astype(int)\n",
    "hla_lr.columns = hla_lr.columns.astype(int)\n",
    "hla_eplet.columns = hla_eplet.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of each locus \n",
    "base = '/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/locis_por_separado/BR/'\n",
    "mats = {\n",
    "    'A': 'mismatch_BR_A.csv',\n",
    "    'B': 'mismatch_BR_B.csv',\n",
    "    'C': 'mismatch_BR_C.csv',\n",
    "    'DQ': 'mismatch_BR_DQ.csv',\n",
    "    'DR': 'mismatch_BR_DR.csv'\n",
    "}\n",
    "\n",
    "matrix_mismatch = {}\n",
    "for locus, archive in mats.items():\n",
    "    matrix_mismatch[locus] = pd.read_csv(base + archive, index_col=0)\n",
    "\n",
    "mismatch_ClassI = (\n",
    "    matrix_mismatch['A'] +\n",
    "    matrix_mismatch['B'] +\n",
    "    matrix_mismatch['C']\n",
    ")\n",
    "\n",
    "mismatch_DQ = matrix_mismatch['DQ']\n",
    "mismatch_DR = matrix_mismatch['DR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismatch to HLA score\n",
    "HLA_DR = 2 - mismatch_DR\n",
    "HLA_DQ = 2- mismatch_DQ\n",
    "HLA_C1 = 6 - mismatch_ClassI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of initial graph with graph resolution and a minimum of quality (k)\n",
    "def create_graph(pairs, compatibility, hla1, k):\n",
    "    G = nx.DiGraph()\n",
    "    added_edges = 0\n",
    "    for i in pairs.index:\n",
    "        for j in pairs.index:\n",
    "            if compatibility.at[i, j] == 1 and hla1.at[i, j] >= k:\n",
    "                G.add_edge(j, i, weight=hla1.at[i, j])\n",
    "                added_edges += 1\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing initial weights to optimization weights on the initial graph arcs\n",
    "def changing_resolution_weights(G, hla2):\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        try:\n",
    "            data['weight'] = hla2.iloc[int(v), int(u)]\n",
    "        except KeyError:\n",
    "            print(f\"No se encontr√≥ peso para el arco ({u}, {v})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al actualizar peso para el arco ({u}, {v}): {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization function \n",
    "def optimization(G, l=3, k=3):\n",
    "    total_cycles = list(nx.simple_cycles(G, length_bound=3))\n",
    "    valid_cycles = [cycle for cycle in total_cycles if len(cycle) <= l and all(G[u][v]['weight'] >= k for u, v in zip(cycle, cycle[1:] + cycle[:1]))]\n",
    "        \n",
    "    P = len(G.nodes())  # \"m\" of the paper\n",
    "    Z = 10 # 10 for antigen and allele level. Change to 138 for eplet level optimization\n",
    "\n",
    "    # Optimization model\n",
    "    m = Model(\"optimization\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    x = {tuple(cycle): m.addVar(vtype=GRB.BINARY, name=f\"x_{'_'.join(map(str, cycle))}\") for cycle in valid_cycles}\n",
    "\n",
    "    m.setObjective(\n",
    "        quicksum(\n",
    "            x[tuple(cycle)] * (\n",
    "                (len(cycle) + (1 / P) * sum(G[u][v]['weight'] / Z for u, v in zip(cycle, cycle[1:] + cycle[:1])))\n",
    "                / P\n",
    "            )\n",
    "            for cycle in valid_cycles\n",
    "        ),\n",
    "        GRB.MAXIMIZE\n",
    "    )\n",
    "\n",
    "    # Restriction\n",
    "    for i in G.nodes():\n",
    "        m.addConstr(quicksum(x[tuple(cycle)] for cycle in valid_cycles if i in cycle) <= 1, name=f\"node_usage_{i}\")\n",
    "\n",
    "    m.optimize()\n",
    "\n",
    "    G_optimal = nx.DiGraph()\n",
    "    selected_cycles = []\n",
    "\n",
    "    if m.status == GRB.OPTIMAL:\n",
    "        for cycle in valid_cycles:\n",
    "            if x[tuple(cycle)].X > 0.5:\n",
    "                selected_cycles.append(cycle)\n",
    "                for i in range(len(cycle)):\n",
    "                    u, v = cycle[i], cycle[(i + 1) % len(cycle)]\n",
    "                    G_optimal.add_edge(u, v, weight=G[u][v]['weight'])\n",
    "\n",
    "    return G_optimal, selected_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete definition of the simulation\n",
    "\n",
    "def update_matrices(indexes, df):\n",
    "    return df.iloc[indexes, indexes]\n",
    "frequiency_waiting_nodes = {}\n",
    "\n",
    "def run_simulation(total_time, arrival_rate, departure_rate, match_run, pairs, compatibility, hla_lr, hla_hr, hla_eplet):\n",
    "    # Evaluation at different resolutions\n",
    "    lr_quality_ethcat1 = []\n",
    "    lr_quality_ethcat2 = []\n",
    "    lr_quality_ethcat4 = []\n",
    "    lr_quality_ethcat5 = []\n",
    "    lr_quality_ethcat6 = []\n",
    "    lr_quality_ethcat7 = []\n",
    "    \n",
    "    hr_quality_ethcat1 = []\n",
    "    hr_quality_ethcat2 = []\n",
    "    hr_quality_ethcat4 = []\n",
    "    hr_quality_ethcat5 = []\n",
    "    hr_quality_ethcat6 = []\n",
    "    hr_quality_ethcat7 = []\n",
    "\n",
    "    e_quality_ethcat1 = []\n",
    "    e_quality_ethcat2 = []\n",
    "    e_quality_ethcat4 = []\n",
    "    e_quality_ethcat5 = []\n",
    "    e_quality_ethcat6 = []\n",
    "    e_quality_ethcat7 = []\n",
    "\n",
    "    waiting_list = []\n",
    "    waiting_times = {}  \n",
    "    arrivals_by_ethcat = {}\n",
    "    historial_cycles = []\n",
    "    historial_departures = []\n",
    "    cont=0\n",
    "    available_indexes = set(pairs.index)\n",
    "\n",
    "    \n",
    "    departures_by_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_classI_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DR_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DQ_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "\n",
    "    # Simulation per month\n",
    "    for month in range(total_time):\n",
    "     \n",
    "        selected_cycles = []\n",
    "       \n",
    "        new_entries = np.random.poisson(arrival_rate)\n",
    "        new_entries = min(new_entries, len(available_indexes))\n",
    "        new_index = np.random.choice(list(available_indexes), size=new_entries, replace=False)\n",
    "        cont+= len(new_index)\n",
    "        waiting_list.extend(new_index)\n",
    "        available_indexes.difference_update(new_index)\n",
    "\n",
    "        for idx in new_index:\n",
    "            waiting_times[idx] = {'arrival': month}\n",
    "            ethnicity = recipients.loc[recipients['Nodo'] == idx, 'ETHCAT'].iloc[0]\n",
    "            if ethnicity in arrivals_by_ethcat:\n",
    "                arrivals_by_ethcat[ethnicity] += 1\n",
    "            else:\n",
    "                arrivals_by_ethcat[ethnicity] = 1\n",
    "        \n",
    " \n",
    "        departure = np.random.poisson(departure_rate)\n",
    "        departure_indexes = [] \n",
    "        if departure:\n",
    "            departure = min(departure, len(waiting_list))\n",
    "            departure_indexes = np.random.choice(waiting_list, size=departure, replace=False)\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in departure_indexes]\n",
    "            historial_departures.extend(departure_indexes)\n",
    "\n",
    "        for idx in departure_indexes:\n",
    "            ethnicity = recipients.loc[idx, 'ETHCAT']\n",
    "            departures_by_ethcat[ethnicity].append(idx)\n",
    "\n",
    "        if (month + 1) % match_run == 0:\n",
    "            waiting_list_index = waiting_list.copy()\n",
    "            df_waiting_list = pairs.loc[waiting_list_index]\n",
    "            \n",
    "            filtered_compatibility = update_matrices(waiting_list_index, compatibility)\n",
    "            filtered_weight = update_matrices(waiting_list_index, hla_lr) # Insert the resolution data that you want for create the graph\n",
    "            \n",
    "            G = create_graph(df_waiting_list, filtered_compatibility, filtered_weight, k= 3) # Insert the minimum weight for create the graph \n",
    "            changing_resolution_weights(G, hla_lr) # Insert the resolution data that you want for the optimization\n",
    "            \n",
    "            G_optimal, selected_cycles = optimization(G, l=3, k=3) # Insert the minimum quality that you want for the cycles \n",
    "\n",
    "            for u, v, data in G_optimal.edges(data=True):\n",
    "                node_ethcat = recipients.loc[v, 'ETHCAT'] \n",
    "                \n",
    "                # HLA for differents loci (optimization resolution)\n",
    "                value_HLA_classI = HLA_C1.iloc[v, u]\n",
    "                value_HLA_DR = HLA_DR.iloc[v, u]\n",
    "                value_HLA_DQ = HLA_DQ.iloc[v, u]\n",
    "\n",
    "                HLA_classI_ethcat[node_ethcat].append(value_HLA_classI)\n",
    "                HLA_DR_ethcat[node_ethcat].append(value_HLA_DR)\n",
    "                HLA_DQ_ethcat[node_ethcat].append(value_HLA_DQ)\n",
    "\n",
    "\n",
    "                if node_ethcat == 1:\n",
    "                    lr_quality_ethcat1.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat1.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat1.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 2:\n",
    "                    lr_quality_ethcat2.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat2.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat2.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 4:\n",
    "                    lr_quality_ethcat4.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat4.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat4.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 5:\n",
    "                    lr_quality_ethcat5.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat5.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat5.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 6:\n",
    "                    lr_quality_ethcat6.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat6.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat6.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 7:\n",
    "                    lr_quality_ethcat7.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat7.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat7.append(hla_eplet.iloc[v, u])\n",
    "            historial_cycles.extend(selected_cycles)\n",
    "\n",
    "            nodes_in_cycles = [node for cycle in selected_cycles for node in cycle]\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in nodes_in_cycles]\n",
    "            for idx in nodes_in_cycles:\n",
    "                waiting_times[idx]['departure'] = month\n",
    "\n",
    "    nodes_in_historial = [node for cycle in historial_cycles for node in cycle]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for idx in nodes_in_historial:\n",
    "        if idx in waiting_times:\n",
    "            waiting_time = waiting_times[idx]['departure'] - waiting_times[idx]['arrival']\n",
    "            ethnicity = recipients.loc[idx, 'ETHCAT'] \n",
    "            data.append({'node': idx, 'waiting time (months)': waiting_time, 'ethnicity': ethnicity})\n",
    "\n",
    "    \n",
    "\n",
    "    df_ethnicity = pd.DataFrame(data)\n",
    "    df_ethnicity['ethnicity'] = df_ethnicity['ethnicity'].astype(int)\n",
    "    df_ethnicity1 = df_ethnicity[df_ethnicity['ethnicity'] == 1]\n",
    "    df_ethnicity2 = df_ethnicity[df_ethnicity['ethnicity'] == 2]\n",
    "    df_ethnicity4 = df_ethnicity[df_ethnicity['ethnicity'] == 4]\n",
    "    df_ethnicity5 = df_ethnicity[df_ethnicity['ethnicity'] == 5]\n",
    "    df_ethnicity6 = df_ethnicity[df_ethnicity['ethnicity'] == 6]\n",
    "    df_ethnicity7 = df_ethnicity[df_ethnicity['ethnicity'] == 7]\n",
    "    waiting_time_mean_1 = df_ethnicity1['waiting time (months)'].mean()\n",
    "    waiting_time_mean_2 = df_ethnicity2['waiting time (months)'].mean()\n",
    "    waiting_time_mean_4 = df_ethnicity4['waiting time (months)'].mean()\n",
    "    waiting_time_mean_5 = df_ethnicity5['waiting time (months)'].mean()\n",
    "    waiting_time_mean_6 = df_ethnicity6['waiting time (months)'].mean()\n",
    "    waiting_time_mean_7 = df_ethnicity7['waiting time (months)'].mean()\n",
    "\n",
    "    \n",
    "    outgoing_per_ethcat = {e: len(departures_by_ethcat[e]) for e in [1,2,4,5,6,7]}\n",
    "    L_per_ethcat  = {e: outgoing_per_ethcat [e] / arrivals_by_ethcat.get(e, 1) for e in outgoing_per_ethcat } \n",
    "    F_per_ethcat  = {e: len([c for c in historial_cycles for n in c if recipients.loc[n,'ETHCAT']==e]) / arrivals_by_ethcat.get(e, 1)\n",
    "                   for e in [1,2,4,5,6,7]}  \n",
    "    \n",
    "     \n",
    "    total_trasplants = sum(len(cycle) for cycle in historial_cycles)\n",
    "    total_entries = sum(arrivals_by_ethcat.values())\n",
    "    F_total = total_trasplants / total_entries if total_entries > 0 else 0\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "    return {\n",
    "        'historial_cycles': historial_cycles,\n",
    "        'historial_departures': historial_departures,\n",
    "        'entries_nodes': cont,\n",
    "        'arrivals_by_ethcat': arrivals_by_ethcat,\n",
    "        'waiting_time_mean1':   waiting_time_mean_1 ,\n",
    "        'waiting_time_mean2':   waiting_time_mean_2,\n",
    "        'waiting_time_mean4':   waiting_time_mean_4,\n",
    "        'waiting_time_mean5':   waiting_time_mean_5,\n",
    "        'waiting_time_mean6':   waiting_time_mean_6,\n",
    "        'waiting_time_mean7':   waiting_time_mean_7,\n",
    "        'lr_quality_ethcat1': np.mean(lr_quality_ethcat1),\n",
    "        'lr_quality_ethcat2': np.mean(lr_quality_ethcat2),\n",
    "        'lr_quality_ethcat4': np.mean(lr_quality_ethcat4),\n",
    "        'lr_quality_ethcat5': np.mean(lr_quality_ethcat5),\n",
    "        'lr_quality_ethcat6': np.mean(lr_quality_ethcat6),\n",
    "        'lr_quality_ethcat7': np.mean(lr_quality_ethcat7),\n",
    "\n",
    "        'hr_quality_ethcat1': np.mean(hr_quality_ethcat1),\n",
    "        'hr_quality_ethcat2': np.mean(hr_quality_ethcat2),\n",
    "        'hr_quality_ethcat4': np.mean(hr_quality_ethcat4),\n",
    "        'hr_quality_ethcat5': np.mean(hr_quality_ethcat5),\n",
    "        'hr_quality_ethcat6': np.mean(hr_quality_ethcat6),\n",
    "        'hr_quality_ethcat7': np.mean(hr_quality_ethcat7),\n",
    "\n",
    "        'e_quality_ethcat1': np.mean(e_quality_ethcat1),\n",
    "        'e_quality_ethcat2': np.mean(e_quality_ethcat2),\n",
    "        'e_quality_ethcat4': np.mean(e_quality_ethcat4),\n",
    "        'e_quality_ethcat5': np.mean(e_quality_ethcat5),\n",
    "        'e_quality_ethcat6': np.mean(e_quality_ethcat6),\n",
    "        'e_quality_ethcat7': np.mean(e_quality_ethcat7),\n",
    "        'avg_ClassI_HLA_ethcat1': np.mean(HLA_classI_ethcat[1]), \n",
    "        'avg_ClassI_HLA_ethcat2': np.mean(HLA_classI_ethcat[2]),\n",
    "        'avg_ClassI_HLA_ethcat4': np.mean(HLA_classI_ethcat[4]),\n",
    "        'avg_ClassI_HLA_ethcat5': np.mean(HLA_classI_ethcat[5]),\n",
    "        'avg_ClassI_HLA_ethcat6': np.mean(HLA_classI_ethcat[6]),\n",
    "        'avg_ClassI_HLA_ethcat7': np.mean(HLA_classI_ethcat[7]), \n",
    "        'HLA_ClassI_total': np.mean(\n",
    "                                    HLA_classI_ethcat[1] + \n",
    "                                    HLA_classI_ethcat[2] + \n",
    "                                    HLA_classI_ethcat[4] + \n",
    "                                    HLA_classI_ethcat[5] + \n",
    "                                    HLA_classI_ethcat[6] + \n",
    "                                    HLA_classI_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'avg_DR_HLA_ethcat1': np.mean(HLA_DR_ethcat[1]), \n",
    "        'avg_DR_HLA_ethcat2': np.mean(HLA_DR_ethcat[2]),\n",
    "        'avg_DR_HLA_ethcat4': np.mean(HLA_DR_ethcat[4]),\n",
    "        'avg_DR_HLA_ethcat5': np.mean(HLA_DR_ethcat[5]),\n",
    "        'avg_DR_HLA_ethcat6': np.mean(HLA_DR_ethcat[6]),\n",
    "        'avg_DR_HLA_ethcat7': np.mean(HLA_DR_ethcat[7]), \n",
    "        'HLA_DR_total': np.mean(\n",
    "                                    HLA_DR_ethcat[1] + \n",
    "                                    HLA_DR_ethcat[2] + \n",
    "                                    HLA_DR_ethcat[4] + \n",
    "                                    HLA_DR_ethcat[5] + \n",
    "                                    HLA_DR_ethcat[6] + \n",
    "                                    HLA_DR_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'avg_DQ_HLA_ethcat1': np.mean(HLA_DQ_ethcat[1]), \n",
    "        'avg_DQ_HLA_ethcat2': np.mean(HLA_DQ_ethcat[2]),\n",
    "        'avg_DQ_HLA_ethcat4': np.mean(HLA_DQ_ethcat[4]),\n",
    "        'avg_DQ_HLA_ethcat5': np.mean(HLA_DQ_ethcat[5]),\n",
    "        'avg_DQ_HLA_ethcat6': np.mean(HLA_DQ_ethcat[6]),\n",
    "        'avg_DQ_HLA_ethcat7': np.mean(HLA_DQ_ethcat[7]), \n",
    "        'HLA_DQ_total': np.mean(\n",
    "                                    HLA_DQ_ethcat[1] + \n",
    "                                    HLA_DQ_ethcat[2] + \n",
    "                                    HLA_DQ_ethcat[4] + \n",
    "                                    HLA_DQ_ethcat[5] + \n",
    "                                    HLA_DQ_ethcat[6] + \n",
    "                                    HLA_DQ_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'F_per_ethcat': F_per_ethcat,        \n",
    "        'L_per_ethcat' : L_per_ethcat,          \n",
    "        'F_total': F_total,\n",
    "        'lr_quality_total': np.mean(\n",
    "                                    lr_quality_ethcat1 + \n",
    "                                    lr_quality_ethcat2 + \n",
    "                                    lr_quality_ethcat4 + \n",
    "                                    lr_quality_ethcat5 + \n",
    "                                    lr_quality_ethcat6 + \n",
    "                                    lr_quality_ethcat7\n",
    "                                ),\n",
    "        'hr_quality_total': np.mean(\n",
    "                                    hr_quality_ethcat1 + \n",
    "                                    hr_quality_ethcat2 + \n",
    "                                    hr_quality_ethcat4 + \n",
    "                                    hr_quality_ethcat5 + \n",
    "                                    hr_quality_ethcat6 + \n",
    "                                    hr_quality_ethcat7\n",
    "                                ),\n",
    "        'e_quality_total': np.mean(\n",
    "                                    e_quality_ethcat1 + \n",
    "                                    e_quality_ethcat2 + \n",
    "                                    e_quality_ethcat4 + \n",
    "                                    e_quality_ethcat5 + \n",
    "                                    e_quality_ethcat6 + \n",
    "                                    e_quality_ethcat7\n",
    "                                ),\n",
    "        'Waiting_time_mean': pd.concat([\n",
    "                                    df_ethnicity1['waiting time (months)'],\n",
    "                                    df_ethnicity2['waiting time (months)'],\n",
    "                                    df_ethnicity4['waiting time (months)'],\n",
    "                                    df_ethnicity5['waiting time (months)'],\n",
    "                                    df_ethnicity6['waiting time (months)'],\n",
    "                                    df_ethnicity7['waiting time (months)']\n",
    "                                    ]).mean()\n",
    "\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing simulation 1 of 100\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Runing simulation 2 of 100\n",
      "Runing simulation 3 of 100\n",
      "Runing simulation 4 of 100\n",
      "Runing simulation 5 of 100\n",
      "Runing simulation 6 of 100\n",
      "Runing simulation 7 of 100\n",
      "Runing simulation 8 of 100\n",
      "Runing simulation 9 of 100\n",
      "Runing simulation 10 of 100\n",
      "Runing simulation 11 of 100\n",
      "Runing simulation 12 of 100\n",
      "Runing simulation 13 of 100\n",
      "Runing simulation 14 of 100\n",
      "Runing simulation 15 of 100\n",
      "Runing simulation 16 of 100\n",
      "Runing simulation 17 of 100\n",
      "Runing simulation 18 of 100\n",
      "Runing simulation 19 of 100\n",
      "Runing simulation 20 of 100\n",
      "Runing simulation 21 of 100\n",
      "Runing simulation 22 of 100\n",
      "Runing simulation 23 of 100\n",
      "Runing simulation 24 of 100\n",
      "Runing simulation 25 of 100\n",
      "Runing simulation 26 of 100\n",
      "Runing simulation 27 of 100\n",
      "Runing simulation 28 of 100\n",
      "Runing simulation 29 of 100\n",
      "Runing simulation 30 of 100\n",
      "Runing simulation 31 of 100\n",
      "Runing simulation 32 of 100\n",
      "Runing simulation 33 of 100\n",
      "Runing simulation 34 of 100\n",
      "Runing simulation 35 of 100\n",
      "Runing simulation 36 of 100\n",
      "Runing simulation 37 of 100\n",
      "Runing simulation 38 of 100\n",
      "Runing simulation 39 of 100\n",
      "Runing simulation 40 of 100\n",
      "Runing simulation 41 of 100\n",
      "Runing simulation 42 of 100\n",
      "Runing simulation 43 of 100\n",
      "Runing simulation 44 of 100\n",
      "Runing simulation 45 of 100\n",
      "Runing simulation 46 of 100\n",
      "Runing simulation 47 of 100\n",
      "Runing simulation 48 of 100\n",
      "Runing simulation 49 of 100\n",
      "Runing simulation 50 of 100\n",
      "Runing simulation 51 of 100\n",
      "Runing simulation 52 of 100\n",
      "Runing simulation 53 of 100\n",
      "Runing simulation 54 of 100\n",
      "Runing simulation 55 of 100\n",
      "Runing simulation 56 of 100\n",
      "Runing simulation 57 of 100\n",
      "Runing simulation 58 of 100\n",
      "Runing simulation 59 of 100\n",
      "Runing simulation 60 of 100\n",
      "Runing simulation 61 of 100\n",
      "Runing simulation 62 of 100\n",
      "Runing simulation 63 of 100\n",
      "Runing simulation 64 of 100\n",
      "Runing simulation 65 of 100\n",
      "Runing simulation 66 of 100\n",
      "Runing simulation 67 of 100\n",
      "Runing simulation 68 of 100\n",
      "Runing simulation 69 of 100\n",
      "Runing simulation 70 of 100\n",
      "Runing simulation 71 of 100\n",
      "Runing simulation 72 of 100\n",
      "Runing simulation 73 of 100\n",
      "Runing simulation 74 of 100\n",
      "Runing simulation 75 of 100\n",
      "Runing simulation 76 of 100\n",
      "Runing simulation 77 of 100\n",
      "Runing simulation 78 of 100\n",
      "Runing simulation 79 of 100\n",
      "Runing simulation 80 of 100\n",
      "Runing simulation 81 of 100\n",
      "Runing simulation 82 of 100\n",
      "Runing simulation 83 of 100\n",
      "Runing simulation 84 of 100\n",
      "Runing simulation 85 of 100\n",
      "Runing simulation 86 of 100\n",
      "Runing simulation 87 of 100\n",
      "Runing simulation 88 of 100\n",
      "Runing simulation 89 of 100\n",
      "Runing simulation 90 of 100\n",
      "Runing simulation 91 of 100\n",
      "Runing simulation 92 of 100\n",
      "Runing simulation 93 of 100\n",
      "Runing simulation 94 of 100\n",
      "Runing simulation 95 of 100\n",
      "Runing simulation 96 of 100\n",
      "Runing simulation 97 of 100\n",
      "Runing simulation 98 of 100\n",
      "Runing simulation 99 of 100\n",
      "Runing simulation 100 of 100\n"
     ]
    }
   ],
   "source": [
    "# Runing the simulations \n",
    "\n",
    "simulations_results = []\n",
    "for i in range(100):\n",
    "    print(f\"Runing simulation {i + 1} of 100\")\n",
    "    results = run_simulation(\n",
    "        total_time=10*12, \n",
    "        arrival_rate=(990/(10*12)), \n",
    "        departure_rate=((990/(10*12))*0.29), \n",
    "        match_run=3,\n",
    "        pairs=pairs, \n",
    "        compatibility=compatibility, \n",
    "        hla_lr = hla_lr,\n",
    "        hla_hr=hla_hr,\n",
    "        hla_eplet= hla_eplet\n",
    "    )\n",
    "   \n",
    "    simulations_results.append({\n",
    "        'simulation': i + 1,\n",
    "        'cycles': results['historial_cycles'],\n",
    "        'total_cycles': len(results['historial_cycles']),\n",
    "        'total_departures': len(results['historial_departures']),\n",
    "        'total_entries': results['entries_nodes'],\n",
    "        'arrivals_by_ethcat': results['arrivals_by_ethcat'],\n",
    "        'waiting_time_mean1':   results['waiting_time_mean1'] ,\n",
    "        'waiting_time_mean2':   results['waiting_time_mean2'],\n",
    "        'waiting_time_mean4':   results['waiting_time_mean4'],\n",
    "        'waiting_time_mean5':   results['waiting_time_mean5'],\n",
    "        'waiting_time_mean6':   results['waiting_time_mean6'],\n",
    "        'waiting_time_mean7':   results['waiting_time_mean7'],\n",
    "        'lr_quality_ethcat1': results['lr_quality_ethcat1'],\n",
    "        'lr_quality_ethcat2': results['lr_quality_ethcat2'],\n",
    "        'lr_quality_ethcat4': results['lr_quality_ethcat4'],\n",
    "        'lr_quality_ethcat5': results['lr_quality_ethcat5'],\n",
    "        'lr_quality_ethcat6': results['lr_quality_ethcat6'],\n",
    "        'lr_quality_ethcat7': results['lr_quality_ethcat7'],\n",
    "        'hr_quality_ethcat1': results['hr_quality_ethcat1'],\n",
    "        'hr_quality_ethcat2': results['hr_quality_ethcat2'],\n",
    "        'hr_quality_ethcat4': results['hr_quality_ethcat4'],\n",
    "        'hr_quality_ethcat5': results['hr_quality_ethcat5'],\n",
    "        'hr_quality_ethcat6': results['hr_quality_ethcat6'],\n",
    "        'hr_quality_ethcat7': results['hr_quality_ethcat7'],\n",
    "        'e_quality_ethcat1': results['e_quality_ethcat1'],\n",
    "        'e_quality_ethcat2': results['e_quality_ethcat2'],\n",
    "        'e_quality_ethcat4': results['e_quality_ethcat4'],\n",
    "        'e_quality_ethcat5': results['e_quality_ethcat5'],\n",
    "        'e_quality_ethcat6': results['e_quality_ethcat6'],\n",
    "        'e_quality_ethcat7': results['e_quality_ethcat7'],\n",
    "        'avg_ClassI_HLA_ethcat1': results['avg_ClassI_HLA_ethcat1'],\n",
    "        'avg_ClassI_HLA_ethcat2': results['avg_ClassI_HLA_ethcat2'],\n",
    "        'avg_ClassI_HLA_ethcat4': results['avg_ClassI_HLA_ethcat4'],\n",
    "        'avg_ClassI_HLA_ethcat5': results['avg_ClassI_HLA_ethcat5'],\n",
    "        'avg_ClassI_HLA_ethcat6': results['avg_ClassI_HLA_ethcat6'],\n",
    "        'avg_ClassI_HLA_ethcat7': results['avg_ClassI_HLA_ethcat7'],\n",
    "        'HLA_ClassI_total': results['HLA_ClassI_total'],\n",
    "\n",
    "        'avg_DR_HLA_ethcat1': results['avg_DR_HLA_ethcat1'],\n",
    "        'avg_DR_HLA_ethcat2': results['avg_DR_HLA_ethcat2'],\n",
    "        'avg_DR_HLA_ethcat4': results['avg_DR_HLA_ethcat4'],\n",
    "        'avg_DR_HLA_ethcat5': results['avg_DR_HLA_ethcat5'],\n",
    "        'avg_DR_HLA_ethcat6': results['avg_DR_HLA_ethcat6'],\n",
    "        'avg_DR_HLA_ethcat7': results['avg_DR_HLA_ethcat7'],\n",
    "        'HLA_DR_total': results['HLA_DR_total'],\n",
    "        \n",
    "\n",
    "        'avg_DQ_HLA_ethcat1': results['avg_DQ_HLA_ethcat1'],\n",
    "        'avg_DQ_HLA_ethcat2': results['avg_DQ_HLA_ethcat2'],\n",
    "        'avg_DQ_HLA_ethcat4': results['avg_DQ_HLA_ethcat4'],\n",
    "        'avg_DQ_HLA_ethcat5': results['avg_DQ_HLA_ethcat5'],\n",
    "        'avg_DQ_HLA_ethcat6': results['avg_DQ_HLA_ethcat6'],\n",
    "        'avg_DQ_HLA_ethcat7': results['avg_DQ_HLA_ethcat7'],\n",
    "        'HLA_DQ_total': results['HLA_DQ_total'],\n",
    "\n",
    "        'F_per_ethcat':   results['F_per_ethcat'],   \n",
    "        'L_per_ethcat':   results['L_per_ethcat'],   \n",
    "        'F_total': results['F_total'],\n",
    "        'lr_quality_total': results['lr_quality_total'],\n",
    "        'hr_quality_total': results['hr_quality_total'],\n",
    "        'e_quality_total': results['e_quality_total'],\n",
    "        'Waiting_time_mean': results['Waiting_time_mean']\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(simulations_results)\n",
    "\n",
    "list_HLA_ClassI_total = df_results['HLA_ClassI_total'].tolist()\n",
    "\n",
    "\n",
    "list_HLA_DR_total = df_results['HLA_DR_total'].tolist()\n",
    "\n",
    "\n",
    "list_HLA_DQ_total = df_results['HLA_DQ_total'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "lists_ClassI = {\n",
    "    1: df_results['avg_ClassI_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_ClassI_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_ClassI_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_ClassI_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_ClassI_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_ClassI_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n",
    "lists_DR = {\n",
    "    1: df_results['avg_DR_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_DR_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_DR_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_DR_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_DR_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_DR_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n",
    "lists_DQ = {\n",
    "    1: df_results['avg_DQ_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_DQ_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_DQ_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_DQ_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_DQ_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_DQ_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity(s)</th>\n",
       "      <th>Arrivals</th>\n",
       "      <th>Transplants</th>\n",
       "      <th>F(s) (Matched)</th>\n",
       "      <th>HLA(s) Antigen</th>\n",
       "      <th>HLA(s) Allele</th>\n",
       "      <th>HLA(s) Eplets</th>\n",
       "      <th>Waiting Time</th>\n",
       "      <th>L(s) (Left Unmatched)</th>\n",
       "      <th>1-F(s)-L(s) (Still in KEP)</th>\n",
       "      <th>HLA ClassI</th>\n",
       "      <th>HLA DR</th>\n",
       "      <th>HLA DQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>591.60</td>\n",
       "      <td>412.78</td>\n",
       "      <td>0.698 [0.693; 0.702]</td>\n",
       "      <td>4.694 [4.681; 4.708]</td>\n",
       "      <td>3.383 [3.368; 3.399]</td>\n",
       "      <td>93.096 [92.975; 93.217]</td>\n",
       "      <td>2.90700</td>\n",
       "      <td>0.271 [0.267; 0.275]</td>\n",
       "      <td>0.031</td>\n",
       "      <td>2.561 [2.551; 2.571]</td>\n",
       "      <td>0.944 [0.939; 0.949]</td>\n",
       "      <td>1.189 [1.185; 1.194]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>169.95</td>\n",
       "      <td>107.86</td>\n",
       "      <td>0.635 [0.627; 0.642]</td>\n",
       "      <td>4.151 [4.130; 4.171]</td>\n",
       "      <td>2.544 [2.523; 2.565]</td>\n",
       "      <td>90.804 [90.600; 91.008]</td>\n",
       "      <td>3.16800</td>\n",
       "      <td>0.326 [0.319; 0.334]</td>\n",
       "      <td>0.039</td>\n",
       "      <td>2.131 [2.115; 2.148]</td>\n",
       "      <td>0.848 [0.837; 0.859]</td>\n",
       "      <td>1.171 [1.161; 1.181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>147.33</td>\n",
       "      <td>91.62</td>\n",
       "      <td>0.622 [0.614; 0.629]</td>\n",
       "      <td>4.301 [4.272; 4.329]</td>\n",
       "      <td>2.656 [2.629; 2.683]</td>\n",
       "      <td>91.045 [90.793; 91.298]</td>\n",
       "      <td>3.51500</td>\n",
       "      <td>0.334 [0.326; 0.343]</td>\n",
       "      <td>0.044</td>\n",
       "      <td>2.330 [2.304; 2.357]</td>\n",
       "      <td>0.852 [0.841; 0.863]</td>\n",
       "      <td>1.119 [1.107; 1.130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>55.65</td>\n",
       "      <td>34.24</td>\n",
       "      <td>0.615 [0.603; 0.628]</td>\n",
       "      <td>3.959 [3.920; 3.999]</td>\n",
       "      <td>2.076 [2.037; 2.116]</td>\n",
       "      <td>85.063 [84.582; 85.545]</td>\n",
       "      <td>3.67300</td>\n",
       "      <td>0.339 [0.327; 0.352]</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.142 [2.111; 2.173]</td>\n",
       "      <td>0.739 [0.719; 0.759]</td>\n",
       "      <td>1.078 [1.058; 1.098]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7.92</td>\n",
       "      <td>6.09</td>\n",
       "      <td>0.769 [0.745; 0.793]</td>\n",
       "      <td>4.314 [4.229; 4.399]</td>\n",
       "      <td>2.976 [2.853; 3.099]</td>\n",
       "      <td>85.085 [84.224; 85.946]</td>\n",
       "      <td>2.10600</td>\n",
       "      <td>0.201 [0.179; 0.224]</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.253 [2.175; 2.332]</td>\n",
       "      <td>0.901 [0.849; 0.952]</td>\n",
       "      <td>1.160 [1.117; 1.203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5.97</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.483 [0.449; 0.517]</td>\n",
       "      <td>4.028 [3.905; 4.151]</td>\n",
       "      <td>2.234 [2.076; 2.392]</td>\n",
       "      <td>93.194 [91.848; 94.541]</td>\n",
       "      <td>4.61000</td>\n",
       "      <td>0.448 [0.410; 0.486]</td>\n",
       "      <td>0.069</td>\n",
       "      <td>2.106 [1.990; 2.222]</td>\n",
       "      <td>0.758 [0.688; 0.829]</td>\n",
       "      <td>1.163 [1.088; 1.239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Entire Population</td>\n",
       "      <td>978.42</td>\n",
       "      <td>655.47</td>\n",
       "      <td>0.670 [0.666; 0.674]</td>\n",
       "      <td>4.505 [4.494; 4.516]</td>\n",
       "      <td>3.066 [3.054; 3.078]</td>\n",
       "      <td>91.935 [91.840; 92.031]</td>\n",
       "      <td>3.08009</td>\n",
       "      <td>0.295 [0.291; 0.299]</td>\n",
       "      <td>0.035</td>\n",
       "      <td>2.431 [2.423; 2.440]</td>\n",
       "      <td>0.903 [0.899; 0.907]</td>\n",
       "      <td>1.170 [1.166; 1.174]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ethnicity(s)  Arrivals  Transplants        F(s) (Matched)  \\\n",
       "0                  1    591.60       412.78  0.698 [0.693; 0.702]   \n",
       "1                  2    169.95       107.86  0.635 [0.627; 0.642]   \n",
       "2                  4    147.33        91.62  0.622 [0.614; 0.629]   \n",
       "3                  5     55.65        34.24  0.615 [0.603; 0.628]   \n",
       "4                  6      7.92         6.09  0.769 [0.745; 0.793]   \n",
       "5                  7      5.97         2.88  0.483 [0.449; 0.517]   \n",
       "6  Entire Population    978.42       655.47  0.670 [0.666; 0.674]   \n",
       "\n",
       "         HLA(s) Antigen         HLA(s) Allele            HLA(s) Eplets  \\\n",
       "0  4.694 [4.681; 4.708]  3.383 [3.368; 3.399]  93.096 [92.975; 93.217]   \n",
       "1  4.151 [4.130; 4.171]  2.544 [2.523; 2.565]  90.804 [90.600; 91.008]   \n",
       "2  4.301 [4.272; 4.329]  2.656 [2.629; 2.683]  91.045 [90.793; 91.298]   \n",
       "3  3.959 [3.920; 3.999]  2.076 [2.037; 2.116]  85.063 [84.582; 85.545]   \n",
       "4  4.314 [4.229; 4.399]  2.976 [2.853; 3.099]  85.085 [84.224; 85.946]   \n",
       "5  4.028 [3.905; 4.151]  2.234 [2.076; 2.392]  93.194 [91.848; 94.541]   \n",
       "6  4.505 [4.494; 4.516]  3.066 [3.054; 3.078]  91.935 [91.840; 92.031]   \n",
       "\n",
       "   Waiting Time L(s) (Left Unmatched) 1-F(s)-L(s) (Still in KEP)  \\\n",
       "0       2.90700  0.271 [0.267; 0.275]                      0.031   \n",
       "1       3.16800  0.326 [0.319; 0.334]                      0.039   \n",
       "2       3.51500  0.334 [0.326; 0.343]                      0.044   \n",
       "3       3.67300  0.339 [0.327; 0.352]                      0.045   \n",
       "4       2.10600  0.201 [0.179; 0.224]                       0.03   \n",
       "5       4.61000  0.448 [0.410; 0.486]                      0.069   \n",
       "6       3.08009  0.295 [0.291; 0.299]                      0.035   \n",
       "\n",
       "             HLA ClassI                HLA DR                HLA DQ  \n",
       "0  2.561 [2.551; 2.571]  0.944 [0.939; 0.949]  1.189 [1.185; 1.194]  \n",
       "1  2.131 [2.115; 2.148]  0.848 [0.837; 0.859]  1.171 [1.161; 1.181]  \n",
       "2  2.330 [2.304; 2.357]  0.852 [0.841; 0.863]  1.119 [1.107; 1.130]  \n",
       "3  2.142 [2.111; 2.173]  0.739 [0.719; 0.759]  1.078 [1.058; 1.098]  \n",
       "4  2.253 [2.175; 2.332]  0.901 [0.849; 0.952]  1.160 [1.117; 1.203]  \n",
       "5  2.106 [1.990; 2.222]  0.758 [0.688; 0.829]  1.163 [1.088; 1.239]  \n",
       "6  2.431 [2.423; 2.440]  0.903 [0.899; 0.907]  1.170 [1.166; 1.174]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "ethnicity = [1, 2, 4, 5, 6, 7]\n",
    "n_sim = len(df_results)\n",
    "\n",
    "def media_ci(list):\n",
    "    m = np.mean(list)\n",
    "    s = np.std(list, ddof=1)\n",
    "    low, high = st.t.interval(0.95, len(list)-1, loc=m, scale=s/np.sqrt(len(list)))\n",
    "    return m, f\"{m:.3f} [{low:.3f}; {high:.3f}]\"\n",
    "\n",
    "rows = []\n",
    "# Reporting per ethnicity \n",
    "\n",
    "for e in ethnicity:\n",
    "    arrivals_e = df_results['arrivals_by_ethcat'].apply(lambda d: d.get(e, 0)).sum() / n_sim\n",
    "    transplants_e = df_results['cycles'].apply(\n",
    "        lambda cycles: sum(1 for c in cycles for n in c if recipients.loc[n, 'ETHCAT'] == e)\n",
    "    ).sum() / n_sim\n",
    "\n",
    "    F_vals = df_results['F_per_ethcat'].apply(lambda d: d[e])\n",
    "    _, txt_F = media_ci(F_vals)\n",
    "    std_F = np.std(F_vals, ddof=1)\n",
    "\n",
    "    lr_quality = df_results[f'lr_quality_ethcat{e}']\n",
    "    _, txt_antigen = media_ci(lr_quality)\n",
    "\n",
    "    hr_quality = df_results[f'hr_quality_ethcat{e}']\n",
    "    _, txt_allele = media_ci(hr_quality)\n",
    "\n",
    "    e_quality  = df_results[f'e_quality_ethcat{e}']\n",
    "    _, txt_eplet = media_ci(e_quality)\n",
    "\n",
    "    waiting = df_results[f'waiting_time_mean{e}'].mean()\n",
    "\n",
    "    L_vals = df_results['L_per_ethcat'].apply(lambda d: d[e])\n",
    "    _, txt_L = media_ci(L_vals)\n",
    "\n",
    "    f_mean = np.mean(F_vals)\n",
    "    l_mean = np.mean(L_vals)\n",
    "    still_in_kep = round(1 - f_mean - l_mean, 3)\n",
    "\n",
    "\n",
    "    list_classi = lists_ClassI[e]\n",
    "\n",
    "    _, txt_classi = media_ci(list_classi)\n",
    "\n",
    "    list_dr = lists_DR[e]\n",
    "    _, txt_dr = media_ci(list_dr)\n",
    "\n",
    "    list_dq = lists_DQ[e]\n",
    "    _, txt_dq = media_ci(list_dq)\n",
    "\n",
    "\n",
    "    rows.append({\n",
    "        'Ethnicity(s)': e,\n",
    "        'Arrivals': round(arrivals_e, 2),\n",
    "        'Transplants': round(transplants_e, 2),\n",
    "        'F(s) (Matched)': txt_F,\n",
    "        'HLA(s) Antigen': txt_antigen,\n",
    "        'HLA(s) Allele': txt_allele,\n",
    "        'HLA(s) Eplets': txt_eplet,\n",
    "        'Waiting Time': round(waiting, 3),\n",
    "        'L(s) (Left Unmatched)': txt_L,\n",
    "        '1-F(s)-L(s) (Still in KEP)': still_in_kep,\n",
    "        'HLA ClassI': txt_classi,\n",
    "        'HLA DR': txt_dr,\n",
    "        'HLA DQ': txt_dq,\n",
    "\n",
    "    })\n",
    "\n",
    "# Reporting the totals\n",
    "\n",
    "total_arrivals = sum(df_results['arrivals_by_ethcat'].apply(lambda d: sum(d.values()))) / n_sim\n",
    "total_transplants = df_results['cycles'].apply(lambda cycles: sum(len(c) for c in cycles)).sum() / n_sim\n",
    "F_total = total_transplants / total_arrivals\n",
    "\n",
    "\n",
    "F_s_total, txt_F_total = media_ci(df_results['F_total'])\n",
    "\n",
    "L_vals_flat = (df_results['total_departures'] / df_results['total_entries']).tolist()\n",
    "L_s_total, ic_L_total = media_ci(L_vals_flat)\n",
    "txt_L_total = ic_L_total\n",
    "\n",
    "_, txt_total_lr_quality = media_ci(df_results['lr_quality_total'])\n",
    "_,txt_total_hr_quality = media_ci(df_results['hr_quality_total'])\n",
    "_,txt_total_e_quality= media_ci(df_results['e_quality_total'])\n",
    "\n",
    "txt_waiting_time_mean = np.mean(df_results['Waiting_time_mean'])\n",
    "\n",
    "F_vals_flat = [df_results['F_per_ethcat'].iloc[i][e] for i in range(n_sim) for e in ethnicity]\n",
    "std_F_total = np.std(F_vals_flat, ddof=1)\n",
    "\n",
    "f_total_mean = F_total  \n",
    "total_outgoing = sum(\n",
    "    df_results['L_per_ethcat'].apply(lambda d: sum(d.values()))\n",
    ") / n_sim\n",
    "\n",
    "l_total_mean = total_outgoing / total_arrivals\n",
    "still_in_kep_total = round(1 - F_total - l_total_mean, 3)\n",
    "\n",
    "\n",
    "_, txt_classi_total = media_ci(list_HLA_ClassI_total)\n",
    "\n",
    "_, txt_dr_total = media_ci(list_HLA_DR_total )\n",
    "\n",
    "_, txt_dq_total = media_ci(list_HLA_DQ_total )\n",
    "\n",
    "rows.append({\n",
    "    'Ethnicity(s)': 'Entire Population',\n",
    "    'Arrivals': round(total_arrivals, 2),\n",
    "    'Transplants': round(total_transplants, 2),\n",
    "    'F(s) (Matched)': txt_F_total,\n",
    "    'HLA(s) Antigen': txt_total_lr_quality,\n",
    "    'HLA(s) Allele': txt_total_hr_quality,\n",
    "    'HLA(s) Eplets': txt_total_e_quality,\n",
    "    'Waiting Time': txt_waiting_time_mean,\n",
    "    'L(s) (Left Unmatched)': txt_L_total,\n",
    "    '1-F(s)-L(s) (Still in KEP)': f\"{(1 - L_s_total - F_s_total):.3f}\",\n",
    "    'HLA ClassI': txt_classi_total,\n",
    "    'HLA DR': txt_dr_total,\n",
    "    'HLA DQ': txt_dq_total\n",
    "})\n",
    "\n",
    "df_final_table = pd.DataFrame(rows)\n",
    "display(df_final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_table.to_excel(\"ofresults_BRBR.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
