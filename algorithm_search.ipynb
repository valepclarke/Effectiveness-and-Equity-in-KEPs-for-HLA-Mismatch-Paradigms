{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***algorithm search***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import networkx as nx\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import random\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "#Compatibility\n",
    "compatibility = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/compatibilidad_total.csv', index_col=0)\n",
    "compatibility.index = range(len(compatibility))\n",
    "compatibility.columns = range(len(compatibility.columns))\n",
    "#Pairs, recipients and donors\n",
    "pairs = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/parejas.csv',index_col=0)\n",
    "recipients = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/receptores.csv',index_col=0)\n",
    "donors = pd.read_csv('/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/donantes.csv',index_col=0)\n",
    "#Weights\n",
    "hla_hr = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_ar.csv\",index_col=0)\n",
    "hla_lr = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_BR.csv\",index_col=0)\n",
    "hla_eplet = pd.read_csv(\"/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/peso_eplet.csv\",index_col=0)\n",
    "hla_hr.columns = hla_hr.columns.astype(int)\n",
    "hla_lr.columns = hla_lr.columns.astype(int)\n",
    "hla_eplet.columns = hla_eplet.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of each locus \n",
    "base = '/Users/valentina/Library/CloudStorage/OneDrive - UAI/TESIS/CODIGO/Datas_simulaciones/locis_por_separado/BR/'\n",
    "mats = {\n",
    "    'A': 'mismatch_BR_A.csv',\n",
    "    'B': 'mismatch_BR_B.csv',\n",
    "    'C': 'mismatch_BR_C.csv',\n",
    "    'DQ': 'mismatch_BR_DQ.csv',\n",
    "    'DR': 'mismatch_BR_DR.csv'\n",
    "}\n",
    "\n",
    "matrix_mismatch = {}\n",
    "for locus, archive in mats.items():\n",
    "    matrix_mismatch[locus] = pd.read_csv(base + archive, index_col=0)\n",
    "\n",
    "mismatch_ClassI = (\n",
    "    matrix_mismatch['A'] +\n",
    "    matrix_mismatch['B'] +\n",
    "    matrix_mismatch['C']\n",
    ")\n",
    "\n",
    "mismatch_DQ = matrix_mismatch['DQ']\n",
    "mismatch_DR = matrix_mismatch['DR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismatch to HLA score\n",
    "HLA_DR = 2 - mismatch_DR\n",
    "HLA_DQ = 2- mismatch_DQ\n",
    "HLA_C1 = 6 - mismatch_ClassI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of initial graph with graph resolution and a minimum of quality (k)\n",
    "def create_graph(pairs, compatibility, hla1, k):\n",
    "    G = nx.DiGraph()\n",
    "    added_edges = 0\n",
    "    for i in pairs.index:\n",
    "        for j in pairs.index:\n",
    "            if compatibility.at[i, j] == 1 and hla1.at[i, j] >= k:\n",
    "                G.add_edge(j, i, weight=hla1.at[i, j])\n",
    "                added_edges += 1\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing initial weights to optimization weights on the initial graph arcs\n",
    "def changing_resolution_weights(G, hla2):\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        try:\n",
    "            data['weight'] = hla2.iloc[int(v), int(u)]\n",
    "        except KeyError:\n",
    "            print(f\"No se encontró peso para el arco ({u}, {v})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al actualizar peso para el arco ({u}, {v}): {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR OPTUNA\n",
    "\n",
    "def optimization(G, multipliers_ethnicity, l=3, k=3):\n",
    "    total_cycles = list(nx.simple_cycles(G, length_bound=3))\n",
    "    valid_cycles = [cycle for cycle in total_cycles if len(cycle) <= l and all(G[u][v]['weight'] >= k for u, v in zip(cycle, cycle[1:] + cycle[:1]))]\n",
    "    \n",
    "    P = len(G.nodes())  \n",
    "    Z = 10\n",
    "\n",
    "\n",
    "\n",
    "    # # ---- imprimir desglose ----\n",
    "    # for cycle in valid_cycles[:5]:  \n",
    "    #     print(f\"\\nCiclo {cycle}:\")\n",
    "    #     term = 0\n",
    "    #     for u, v in zip(cycle, cycle[1:] + cycle[:1]):\n",
    "    #         eth = recipients.loc[v, 'ETHCAT']\n",
    "    #         mult = multipliers_ethnicity.get(eth, 1.0)\n",
    "    #         w = G[u][v]['weight']\n",
    "\n",
    "    #         part1 = mult * 1\n",
    "    #         part2 = mult * (w / (P * Z))\n",
    "\n",
    "    #         term = term + part1 + part2\n",
    "\n",
    "\n",
    "    #         print(f\"  {u}->{v} | ETHCAT={eth} | multiplier={mult}\")\n",
    "    #         print(f\"    multiplier * 1 = {part1:.6f}\")\n",
    "    #         print(f\"    + multiplier * (w/(P*Z)) = {part2:.6f}  (w={w}, P={P}, Z={Z})\")\n",
    "\n",
    "    #     print(\"Term:\", term )\n",
    "    #     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "    m = Model(\"optimization\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    x = {\n",
    "        tuple(cycle): m.addVar(vtype=GRB.BINARY, \n",
    "                               name=f\"x_{'_'.join(map(str, cycle))}\") \n",
    "        for cycle in valid_cycles\n",
    "    }\n",
    "\n",
    "    m.setObjective(\n",
    "        quicksum(\n",
    "            x[tuple(cycle)] * \n",
    "            #(\n",
    "                sum(\n",
    "                multipliers_ethnicity.get(recipients.loc[v, 'ETHCAT'], 1.0) *\n",
    "                (1 + (G[u][v]['weight'] / (P * Z)))\n",
    "                for u, v in zip(cycle, cycle[1:] + cycle[:1])\n",
    "            )\n",
    "            #)/P\n",
    "            \n",
    "            for cycle in valid_cycles\n",
    "        ),\n",
    "        GRB.MAXIMIZE\n",
    "    )\n",
    "\n",
    "    for i in G.nodes():\n",
    "        m.addConstr(quicksum(x[tuple(cycle)] for cycle in valid_cycles if i in cycle) <= 1, \n",
    "                    name=f\"node_usage_{i}\")\n",
    "\n",
    "    try:\n",
    "        m.optimize()\n",
    "    except gp.GurobiError as e:\n",
    "        print(f\"⚠️ Error of Gurobi: {e}\")\n",
    "      \n",
    "        return None, [], True  \n",
    "\n",
    "    G_optimal = nx.DiGraph()\n",
    "    selected_cycles = []\n",
    "\n",
    "    if m.status == GRB.OPTIMAL:\n",
    "        for cycle in valid_cycles:\n",
    "            if x[tuple(cycle)].X > 0.5:\n",
    "                selected_cycles.append(cycle)\n",
    "                for i in range(len(cycle)):\n",
    "                    u, v = cycle[i], cycle[(i + 1) % len(cycle)]\n",
    "                    G_optimal.add_edge(u, v, weight=G[u][v]['weight'])\n",
    "\n",
    "\n",
    "    return G_optimal, selected_cycles, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete definition of the simulation\n",
    "\n",
    "def update_matrices(indexes, df):\n",
    "    return df.iloc[indexes, indexes]\n",
    "frequiency_waiting_nodes = {}\n",
    "\n",
    "def run_simulation(total_time, arrival_rate, departure_rate, match_run, pairs, compatibility, hla_lr, hla_hr, hla_eplet, multipliers_ethnicity, seed= None):\n",
    "    # Evaluation at different resolutions\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    lr_quality_ethcat1 = []\n",
    "    lr_quality_ethcat2 = []\n",
    "    lr_quality_ethcat4 = []\n",
    "    lr_quality_ethcat5 = []\n",
    "    lr_quality_ethcat6 = []\n",
    "    lr_quality_ethcat7 = []\n",
    "    \n",
    "    hr_quality_ethcat1 = []\n",
    "    hr_quality_ethcat2 = []\n",
    "    hr_quality_ethcat4 = []\n",
    "    hr_quality_ethcat5 = []\n",
    "    hr_quality_ethcat6 = []\n",
    "    hr_quality_ethcat7 = []\n",
    "\n",
    "    e_quality_ethcat1 = []\n",
    "    e_quality_ethcat2 = []\n",
    "    e_quality_ethcat4 = []\n",
    "    e_quality_ethcat5 = []\n",
    "    e_quality_ethcat6 = []\n",
    "    e_quality_ethcat7 = []\n",
    "\n",
    "    waiting_list = []\n",
    "    waiting_times = {}  \n",
    "    arrivals_by_ethcat = {}\n",
    "    historial_cycles = []\n",
    "    historial_departures = []\n",
    "    cont=0\n",
    "    available_indexes = set(pairs.index)\n",
    "\n",
    "    \n",
    "    departures_by_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_classI_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DR_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DQ_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "\n",
    "    # Simulation per month\n",
    "    for month in range(total_time):\n",
    "     \n",
    "        selected_cycles = []\n",
    "       \n",
    "        new_entries = np.random.poisson(arrival_rate)\n",
    "        new_entries = min(new_entries, len(available_indexes))\n",
    "        new_index = np.random.choice(list(available_indexes), size=new_entries, replace=False)\n",
    "        cont+= len(new_index)\n",
    "        waiting_list.extend(new_index)\n",
    "        available_indexes.difference_update(new_index)\n",
    "\n",
    "        for idx in new_index:\n",
    "            waiting_times[idx] = {'arrival': month}\n",
    "            ethnicity = recipients.loc[recipients['Nodo'] == idx, 'ETHCAT'].iloc[0]\n",
    "            if ethnicity in arrivals_by_ethcat:\n",
    "                arrivals_by_ethcat[ethnicity] += 1\n",
    "            else:\n",
    "                arrivals_by_ethcat[ethnicity] = 1\n",
    "        \n",
    " \n",
    "        departure = np.random.poisson(departure_rate)\n",
    "        departure_indexes = [] \n",
    "        if departure:\n",
    "            departure = min(departure, len(waiting_list))\n",
    "            departure_indexes = np.random.choice(waiting_list, size=departure, replace=False)\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in departure_indexes]\n",
    "            historial_departures.extend(departure_indexes)\n",
    "\n",
    "        for idx in departure_indexes:\n",
    "            ethnicity = recipients.loc[idx, 'ETHCAT']\n",
    "            departures_by_ethcat[ethnicity].append(idx)\n",
    "\n",
    "        if (month + 1) % match_run == 0:\n",
    "            waiting_list_index = waiting_list.copy()\n",
    "            df_waiting_list = pairs.loc[waiting_list_index]\n",
    "            \n",
    "            filtered_compatibility = update_matrices(waiting_list_index, compatibility)\n",
    "            filtered_weight = update_matrices(waiting_list_index, hla_lr) # Insert the resolution data that you want for create the graph\n",
    "            \n",
    "    \n",
    "            G = create_graph(df_waiting_list, filtered_compatibility, filtered_weight, k= 3) # Insert the minimum weight for create the graph \n",
    "            changing_resolution_weights(G, hla_lr) # Insert the resolution data that you want for the optimization\n",
    "\n",
    "            \n",
    "            \n",
    "            G_optimal, selected_cycles,  error_gurobi = optimization(G, multipliers_ethnicity, l=3, k=3 ) # Insert the minimum quality that you want for the cycles \n",
    "\n",
    "            if error_gurobi:\n",
    "                return float(\"inf\"), None\n",
    "\n",
    "            for u, v, data in G_optimal.edges(data=True):\n",
    "                node_ethcat = recipients.loc[v, 'ETHCAT'] \n",
    "                \n",
    "                # HLA for differents loci (optimization resolution)\n",
    "                #value_HLA_classI = HLA_C1.iloc[v, u]\n",
    "                value_HLA_DR = HLA_DR.iloc[v, u]\n",
    "                value_HLA_DQ = HLA_DQ.iloc[v, u]\n",
    "\n",
    "                #HLA_classI_ethcat[node_ethcat].append(value_HLA_classI)\n",
    "                HLA_DR_ethcat[node_ethcat].append(value_HLA_DR)\n",
    "                HLA_DQ_ethcat[node_ethcat].append(value_HLA_DQ)\n",
    "\n",
    "\n",
    "                if node_ethcat == 1:\n",
    "                    lr_quality_ethcat1.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat1.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat1.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 2:\n",
    "                    lr_quality_ethcat2.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat2.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat2.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 4:\n",
    "                    lr_quality_ethcat4.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat4.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat4.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 5:\n",
    "                    lr_quality_ethcat5.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat5.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat5.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 6:\n",
    "                    lr_quality_ethcat6.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat6.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat6.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 7:\n",
    "                    lr_quality_ethcat7.append(hla_lr.iloc[v, u])\n",
    "                    hr_quality_ethcat7.append(hla_hr.iloc[v, u])\n",
    "                    e_quality_ethcat7.append(hla_eplet.iloc[v, u])\n",
    "            historial_cycles.extend(selected_cycles)\n",
    "\n",
    "            nodes_in_cycles = [node for cycle in selected_cycles for node in cycle]\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in nodes_in_cycles]\n",
    "            for idx in nodes_in_cycles:\n",
    "                waiting_times[idx]['departure'] = month\n",
    "\n",
    "    nodes_in_historial = [node for cycle in historial_cycles for node in cycle]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for idx in nodes_in_historial:\n",
    "        if idx in waiting_times:\n",
    "            waiting_time = waiting_times[idx]['departure'] - waiting_times[idx]['arrival']\n",
    "            ethnicity = recipients.loc[idx, 'ETHCAT'] \n",
    "            data.append({'node': idx, 'waiting time (months)': waiting_time, 'ethnicity': ethnicity})\n",
    "\n",
    "    \n",
    "\n",
    "    df_ethnicity = pd.DataFrame(data)\n",
    "    df_ethnicity['ethnicity'] = df_ethnicity['ethnicity'].astype(int)\n",
    "    df_ethnicity1 = df_ethnicity[df_ethnicity['ethnicity'] == 1]\n",
    "    df_ethnicity2 = df_ethnicity[df_ethnicity['ethnicity'] == 2]\n",
    "    df_ethnicity4 = df_ethnicity[df_ethnicity['ethnicity'] == 4]\n",
    "    df_ethnicity5 = df_ethnicity[df_ethnicity['ethnicity'] == 5]\n",
    "    df_ethnicity6 = df_ethnicity[df_ethnicity['ethnicity'] == 6]\n",
    "    df_ethnicity7 = df_ethnicity[df_ethnicity['ethnicity'] == 7]\n",
    "    waiting_time_mean_1 = df_ethnicity1['waiting time (months)'].mean()\n",
    "    waiting_time_mean_2 = df_ethnicity2['waiting time (months)'].mean()\n",
    "    waiting_time_mean_4 = df_ethnicity4['waiting time (months)'].mean()\n",
    "    waiting_time_mean_5 = df_ethnicity5['waiting time (months)'].mean()\n",
    "    waiting_time_mean_6 = df_ethnicity6['waiting time (months)'].mean()\n",
    "    waiting_time_mean_7 = df_ethnicity7['waiting time (months)'].mean()\n",
    "\n",
    "    \n",
    "    outgoing_per_ethcat = {e: len(departures_by_ethcat[e]) for e in [1,2,4,5,6,7]}\n",
    "    L_per_ethcat  = {e: outgoing_per_ethcat [e] / arrivals_by_ethcat.get(e, 1) for e in outgoing_per_ethcat } \n",
    "    F_per_ethcat  = {e: len([c for c in historial_cycles for n in c if recipients.loc[n,'ETHCAT']==e]) / arrivals_by_ethcat.get(e, 1)\n",
    "                   for e in [1,2,4,5,6,7]}  \n",
    "    \n",
    "     \n",
    "    total_trasplants = sum(len(cycle) for cycle in historial_cycles)\n",
    "    total_entries = sum(arrivals_by_ethcat.values())\n",
    "    F_total = total_trasplants / total_entries if total_entries > 0 else 0\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "    return {\n",
    "        'historial_cycles': historial_cycles,\n",
    "        'historial_departures': historial_departures,\n",
    "        'entries_nodes': cont,\n",
    "        'arrivals_by_ethcat': arrivals_by_ethcat,\n",
    "        'waiting_time_mean1':   waiting_time_mean_1 ,\n",
    "        'waiting_time_mean2':   waiting_time_mean_2,\n",
    "        'waiting_time_mean4':   waiting_time_mean_4,\n",
    "        'waiting_time_mean5':   waiting_time_mean_5,\n",
    "        'waiting_time_mean6':   waiting_time_mean_6,\n",
    "        'waiting_time_mean7':   waiting_time_mean_7,\n",
    "        'lr_quality_ethcat1': np.mean(lr_quality_ethcat1),\n",
    "        'lr_quality_ethcat2': np.mean(lr_quality_ethcat2),\n",
    "        'lr_quality_ethcat4': np.mean(lr_quality_ethcat4),\n",
    "        'lr_quality_ethcat5': np.mean(lr_quality_ethcat5),\n",
    "        'lr_quality_ethcat6': np.mean(lr_quality_ethcat6),\n",
    "        'lr_quality_ethcat7': np.mean(lr_quality_ethcat7),\n",
    "\n",
    "        'hr_quality_ethcat1': np.mean(hr_quality_ethcat1),\n",
    "        'hr_quality_ethcat2': np.mean(hr_quality_ethcat2),\n",
    "        'hr_quality_ethcat4': np.mean(hr_quality_ethcat4),\n",
    "        'hr_quality_ethcat5': np.mean(hr_quality_ethcat5),\n",
    "        'hr_quality_ethcat6': np.mean(hr_quality_ethcat6),\n",
    "        'hr_quality_ethcat7': np.mean(hr_quality_ethcat7),\n",
    "\n",
    "        'e_quality_ethcat1': np.mean(e_quality_ethcat1),\n",
    "        'e_quality_ethcat2': np.mean(e_quality_ethcat2),\n",
    "        'e_quality_ethcat4': np.mean(e_quality_ethcat4),\n",
    "        'e_quality_ethcat5': np.mean(e_quality_ethcat5),\n",
    "        'e_quality_ethcat6': np.mean(e_quality_ethcat6),\n",
    "        'e_quality_ethcat7': np.mean(e_quality_ethcat7),\n",
    "        'avg_ClassI_HLA_ethcat1': np.mean(HLA_classI_ethcat[1]), \n",
    "        'avg_ClassI_HLA_ethcat2': np.mean(HLA_classI_ethcat[2]),\n",
    "        'avg_ClassI_HLA_ethcat4': np.mean(HLA_classI_ethcat[4]),\n",
    "        'avg_ClassI_HLA_ethcat5': np.mean(HLA_classI_ethcat[5]),\n",
    "        'avg_ClassI_HLA_ethcat6': np.mean(HLA_classI_ethcat[6]),\n",
    "        'avg_ClassI_HLA_ethcat7': np.mean(HLA_classI_ethcat[7]), \n",
    "        'HLA_ClassI_total': np.mean(\n",
    "                                    HLA_classI_ethcat[1] + \n",
    "                                    HLA_classI_ethcat[2] + \n",
    "                                    HLA_classI_ethcat[4] + \n",
    "                                    HLA_classI_ethcat[5] + \n",
    "                                    HLA_classI_ethcat[6] + \n",
    "                                    HLA_classI_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'avg_DR_HLA_ethcat1': np.mean(HLA_DR_ethcat[1]), \n",
    "        'avg_DR_HLA_ethcat2': np.mean(HLA_DR_ethcat[2]),\n",
    "        'avg_DR_HLA_ethcat4': np.mean(HLA_DR_ethcat[4]),\n",
    "        'avg_DR_HLA_ethcat5': np.mean(HLA_DR_ethcat[5]),\n",
    "        'avg_DR_HLA_ethcat6': np.mean(HLA_DR_ethcat[6]),\n",
    "        'avg_DR_HLA_ethcat7': np.mean(HLA_DR_ethcat[7]), \n",
    "        'HLA_DR_total': np.mean(\n",
    "                                    HLA_DR_ethcat[1] + \n",
    "                                    HLA_DR_ethcat[2] + \n",
    "                                    HLA_DR_ethcat[4] + \n",
    "                                    HLA_DR_ethcat[5] + \n",
    "                                    HLA_DR_ethcat[6] + \n",
    "                                    HLA_DR_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'avg_DQ_HLA_ethcat1': np.mean(HLA_DQ_ethcat[1]), \n",
    "        'avg_DQ_HLA_ethcat2': np.mean(HLA_DQ_ethcat[2]),\n",
    "        'avg_DQ_HLA_ethcat4': np.mean(HLA_DQ_ethcat[4]),\n",
    "        'avg_DQ_HLA_ethcat5': np.mean(HLA_DQ_ethcat[5]),\n",
    "        'avg_DQ_HLA_ethcat6': np.mean(HLA_DQ_ethcat[6]),\n",
    "        'avg_DQ_HLA_ethcat7': np.mean(HLA_DQ_ethcat[7]), \n",
    "        'HLA_DQ_total': np.mean(\n",
    "                                    HLA_DQ_ethcat[1] + \n",
    "                                    HLA_DQ_ethcat[2] + \n",
    "                                    HLA_DQ_ethcat[4] + \n",
    "                                    HLA_DQ_ethcat[5] + \n",
    "                                    HLA_DQ_ethcat[6] + \n",
    "                                    HLA_DQ_ethcat[7]\n",
    "                                ),\n",
    "\n",
    "        'F_per_ethcat': F_per_ethcat,        \n",
    "        'L_per_ethcat' : L_per_ethcat,          \n",
    "        'F_total': F_total,\n",
    "        'lr_quality_total': np.mean(\n",
    "                                    lr_quality_ethcat1 + \n",
    "                                    lr_quality_ethcat2 + \n",
    "                                    lr_quality_ethcat4 + \n",
    "                                    lr_quality_ethcat5 + \n",
    "                                    lr_quality_ethcat6 + \n",
    "                                    lr_quality_ethcat7\n",
    "                                ),\n",
    "        'hr_quality_total': np.mean(\n",
    "                                    hr_quality_ethcat1 + \n",
    "                                    hr_quality_ethcat2 + \n",
    "                                    hr_quality_ethcat4 + \n",
    "                                    hr_quality_ethcat5 + \n",
    "                                    hr_quality_ethcat6 + \n",
    "                                    hr_quality_ethcat7\n",
    "                                ),\n",
    "        'e_quality_total': np.mean(\n",
    "                                    e_quality_ethcat1 + \n",
    "                                    e_quality_ethcat2 + \n",
    "                                    e_quality_ethcat4 + \n",
    "                                    e_quality_ethcat5 + \n",
    "                                    e_quality_ethcat6 + \n",
    "                                    e_quality_ethcat7\n",
    "                                ),\n",
    "        'Waiting_time_mean': pd.concat([\n",
    "                                    df_ethnicity1['waiting time (months)'],\n",
    "                                    df_ethnicity2['waiting time (months)'],\n",
    "                                    df_ethnicity4['waiting time (months)'],\n",
    "                                    df_ethnicity5['waiting time (months)'],\n",
    "                                    df_ethnicity6['waiting time (months)'],\n",
    "                                    df_ethnicity7['waiting time (months)']\n",
    "                                    ]).mean()\n",
    "\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### For the same seed just in the iterations ######\n",
    "def run_simulation(\n",
    "    total_time,\n",
    "    arrival_rate,\n",
    "    departure_rate,\n",
    "    match_run,\n",
    "    pairs,\n",
    "    compatibility,\n",
    "    hla_lr,\n",
    "    hla_hr,\n",
    "    hla_eplet,\n",
    "    multipliers_ethnicity,\n",
    "    seed=None\n",
    "):\n",
    "    if seed is None:\n",
    "        rng_arr = np.random.RandomState()   # arrivals\n",
    "        rng_dep = np.random.RandomState()   # departures\n",
    "    else:\n",
    "        rng_arr = np.random.RandomState(seed + 1) \n",
    "        rng_dep = np.random.RandomState(seed + 2)  \n",
    "\n",
    "    # accumulators\n",
    "    lr_quality_ethcat1, lr_quality_ethcat2, lr_quality_ethcat4 = [], [], []\n",
    "    lr_quality_ethcat5, lr_quality_ethcat6, lr_quality_ethcat7 = [], [], []\n",
    "    hr_quality_ethcat1, hr_quality_ethcat2, hr_quality_ethcat4 = [], [], []\n",
    "    hr_quality_ethcat5, hr_quality_ethcat6, hr_quality_ethcat7 = [], [], []\n",
    "    e_quality_ethcat1,  e_quality_ethcat2,  e_quality_ethcat4  = [], [], []\n",
    "    e_quality_ethcat5,  e_quality_ethcat6,  e_quality_ethcat7  = [], [], []\n",
    "\n",
    "    waiting_list = []\n",
    "    waiting_times = {}\n",
    "    arrivals_by_ethcat = {}\n",
    "    historial_cycles = []\n",
    "    historial_departures = []\n",
    "    cont = 0\n",
    "\n",
    "    departures_by_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_classI_ethcat = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DR_ethcat     = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "    HLA_DQ_ethcat     = {1: [], 2: [], 4: [], 5: [], 6: [], 7: []}\n",
    "\n",
    "    pool = np.array(pairs.index, copy=True)\n",
    "    pool = rng_arr.permutation(pool)\n",
    "    ptr = 0  \n",
    "\n",
    "    # simulation month per month\n",
    "    for month in range(total_time):\n",
    "        selected_cycles = []\n",
    "\n",
    "        # arrivals\n",
    "        new_entries = int(rng_arr.poisson(arrival_rate))\n",
    "        remaining = len(pool) - ptr\n",
    "        if remaining <= 0:\n",
    "            new_entries = 0\n",
    "        else:\n",
    "            new_entries = min(new_entries, remaining)\n",
    "\n",
    "        if new_entries > 0:\n",
    "            new_index = pool[ptr:ptr + new_entries]\n",
    "            ptr += new_entries\n",
    "            cont += new_entries\n",
    "            waiting_list.extend(new_index.tolist())\n",
    "\n",
    "            for idx in new_index:\n",
    "                waiting_times[idx] = {'arrival': month}\n",
    "                ethnicity = recipients.loc[recipients['Nodo'] == idx, 'ETHCAT'].iloc[0]\n",
    "                arrivals_by_ethcat[ethnicity] = arrivals_by_ethcat.get(ethnicity, 0) + 1\n",
    "\n",
    "        # departures\n",
    "        departure = int(rng_dep.poisson(departure_rate))\n",
    "        if departure > 0 and len(waiting_list) > 0:\n",
    "            departure = min(departure, len(waiting_list))\n",
    "            pos = rng_dep.choice(len(waiting_list), size=departure, replace=False)\n",
    "            pos.sort()\n",
    "            departure_indexes = [waiting_list[p] for p in pos]\n",
    "            keep = set(departure_indexes)\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in keep]\n",
    "            historial_departures.extend(departure_indexes)\n",
    "\n",
    "            for idx in departure_indexes:\n",
    "                ethnicity = recipients.loc[idx, 'ETHCAT']\n",
    "                departures_by_ethcat[ethnicity].append(idx)\n",
    "\n",
    "        # match run\n",
    "        if (month + 1) % match_run == 0 and len(waiting_list) > 0:\n",
    "            waiting_list_index = waiting_list.copy()\n",
    "            df_waiting_list = pairs.loc[waiting_list_index]\n",
    "\n",
    "            filtered_compatibility = update_matrices(waiting_list_index, compatibility)\n",
    "            filtered_weight = update_matrices(waiting_list_index, hla_lr)\n",
    "\n",
    "            G = create_graph(df_waiting_list, filtered_compatibility, filtered_weight, k=3)\n",
    "            changing_resolution_weights(G, hla_lr)\n",
    "\n",
    "            G_optimal, selected_cycles, error_gurobi = optimization(G, multipliers_ethnicity, l=3, k=3)\n",
    "            if error_gurobi:\n",
    "                return float(\"inf\"), None\n",
    "\n",
    "            for u, v, data in G_optimal.edges(data=True):\n",
    "                node_ethcat = recipients.loc[v, 'ETHCAT']\n",
    "\n",
    "                value_HLA_classI = HLA_C1.iloc[v, u]\n",
    "                value_HLA_DR     = HLA_DR.iloc[v, u]\n",
    "                value_HLA_DQ     = HLA_DQ.iloc[v, u]\n",
    "\n",
    "                HLA_classI_ethcat[node_ethcat].append(value_HLA_classI)\n",
    "                HLA_DR_ethcat[node_ethcat].append(value_HLA_DR)\n",
    "                HLA_DQ_ethcat[node_ethcat].append(value_HLA_DQ)\n",
    "\n",
    "                if node_ethcat == 1:\n",
    "                    lr_quality_ethcat1.append(hla_lr.iloc[v, u]); hr_quality_ethcat1.append(hla_hr.iloc[v, u]); e_quality_ethcat1.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 2:\n",
    "                    lr_quality_ethcat2.append(hla_lr.iloc[v, u]); hr_quality_ethcat2.append(hla_hr.iloc[v, u]); e_quality_ethcat2.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 4:\n",
    "                    lr_quality_ethcat4.append(hla_lr.iloc[v, u]); hr_quality_ethcat4.append(hla_hr.iloc[v, u]); e_quality_ethcat4.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 5:\n",
    "                    lr_quality_ethcat5.append(hla_lr.iloc[v, u]); hr_quality_ethcat5.append(hla_hr.iloc[v, u]); e_quality_ethcat5.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 6:\n",
    "                    lr_quality_ethcat6.append(hla_lr.iloc[v, u]); hr_quality_ethcat6.append(hla_hr.iloc[v, u]); e_quality_ethcat6.append(hla_eplet.iloc[v, u])\n",
    "                elif node_ethcat == 7:\n",
    "                    lr_quality_ethcat7.append(hla_lr.iloc[v, u]); hr_quality_ethcat7.append(hla_hr.iloc[v, u]); e_quality_ethcat7.append(hla_eplet.iloc[v, u])\n",
    "\n",
    "            historial_cycles.extend(selected_cycles)\n",
    "\n",
    "            nodes_in_cycles = [node for cycle in selected_cycles for node in cycle]\n",
    "            waiting_list = [idx for idx in waiting_list if idx not in nodes_in_cycles]\n",
    "            for idx in nodes_in_cycles:\n",
    "                waiting_times[idx]['departure'] = month\n",
    "\n",
    "    # some metrics\n",
    "    nodes_in_historial = [node for cycle in historial_cycles for node in cycle]\n",
    "    data = []\n",
    "    for idx in nodes_in_historial:\n",
    "        if idx in waiting_times:\n",
    "            waiting_time = waiting_times[idx]['departure'] - waiting_times[idx]['arrival']\n",
    "            ethnicity = recipients.loc[idx, 'ETHCAT']\n",
    "            data.append({'node': idx, 'waiting time (months)': waiting_time, 'ethnicity': ethnicity})\n",
    "\n",
    "    df_ethnicity = pd.DataFrame(data)\n",
    "    if not df_ethnicity.empty:\n",
    "        df_ethnicity['ethnicity'] = df_ethnicity['ethnicity'].astype(int)\n",
    "        df_ethnicity1 = df_ethnicity[df_ethnicity['ethnicity'] == 1]\n",
    "        df_ethnicity2 = df_ethnicity[df_ethnicity['ethnicity'] == 2]\n",
    "        df_ethnicity4 = df_ethnicity[df_ethnicity['ethnicity'] == 4]\n",
    "        df_ethnicity5 = df_ethnicity[df_ethnicity['ethnicity'] == 5]\n",
    "        df_ethnicity6 = df_ethnicity[df_ethnicity['ethnicity'] == 6]\n",
    "        df_ethnicity7 = df_ethnicity[df_ethnicity['ethnicity'] == 7]\n",
    "        waiting_time_mean_1 = df_ethnicity1['waiting time (months)'].mean()\n",
    "        waiting_time_mean_2 = df_ethnicity2['waiting time (months)'].mean()\n",
    "        waiting_time_mean_4 = df_ethnicity4['waiting time (months)'].mean()\n",
    "        waiting_time_mean_5 = df_ethnicity5['waiting time (months)'].mean()\n",
    "        waiting_time_mean_6 = df_ethnicity6['waiting time (months)'].mean()\n",
    "        waiting_time_mean_7 = df_ethnicity7['waiting time (months)'].mean()\n",
    "    else:\n",
    "        waiting_time_mean_1 = waiting_time_mean_2 = waiting_time_mean_4 = np.nan\n",
    "        waiting_time_mean_5 = waiting_time_mean_6 = waiting_time_mean_7 = np.nan\n",
    "\n",
    "    outgoing_per_ethcat = {e: len(departures_by_ethcat[e]) for e in [1,2,4,5,6,7]}\n",
    "    L_per_ethcat  = {e: outgoing_per_ethcat[e] / arrivals_by_ethcat.get(e, 1) for e in outgoing_per_ethcat}\n",
    "    F_per_ethcat  = {e: len([c for c in historial_cycles for n in c if recipients.loc[n, 'ETHCAT'] == e]) / arrivals_by_ethcat.get(e, 1)\n",
    "                     for e in [1,2,4,5,6,7]}\n",
    "\n",
    "    total_trasplants = sum(len(cycle) for cycle in historial_cycles)\n",
    "    total_entries = sum(arrivals_by_ethcat.values())\n",
    "    F_total = total_trasplants / total_entries if total_entries > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'historial_cycles': historial_cycles,\n",
    "        'historial_departures': historial_departures,\n",
    "        'entries_nodes': cont,\n",
    "        'arrivals_by_ethcat': arrivals_by_ethcat,\n",
    "        'waiting_time_mean1': waiting_time_mean_1,\n",
    "        'waiting_time_mean2': waiting_time_mean_2,\n",
    "        'waiting_time_mean4': waiting_time_mean_4,\n",
    "        'waiting_time_mean5': waiting_time_mean_5,\n",
    "        'waiting_time_mean6': waiting_time_mean_6,\n",
    "        'waiting_time_mean7': waiting_time_mean_7,\n",
    "\n",
    "        'lr_quality_ethcat1': np.mean(lr_quality_ethcat1),\n",
    "        'lr_quality_ethcat2': np.mean(lr_quality_ethcat2),\n",
    "        'lr_quality_ethcat4': np.mean(lr_quality_ethcat4),\n",
    "        'lr_quality_ethcat5': np.mean(lr_quality_ethcat5),\n",
    "        'lr_quality_ethcat6': np.mean(lr_quality_ethcat6),\n",
    "        'lr_quality_ethcat7': np.mean(lr_quality_ethcat7),\n",
    "\n",
    "        'hr_quality_ethcat1': np.mean(hr_quality_ethcat1),\n",
    "        'hr_quality_ethcat2': np.mean(hr_quality_ethcat2),\n",
    "        'hr_quality_ethcat4': np.mean(hr_quality_ethcat4),\n",
    "        'hr_quality_ethcat5': np.mean(hr_quality_ethcat5),\n",
    "        'hr_quality_ethcat6': np.mean(hr_quality_ethcat6),\n",
    "        'hr_quality_ethcat7': np.mean(hr_quality_ethcat7),\n",
    "\n",
    "        'e_quality_ethcat1': np.mean(e_quality_ethcat1),\n",
    "        'e_quality_ethcat2': np.mean(e_quality_ethcat2),\n",
    "        'e_quality_ethcat4': np.mean(e_quality_ethcat4),\n",
    "        'e_quality_ethcat5': np.mean(e_quality_ethcat5),\n",
    "        'e_quality_ethcat6': np.mean(e_quality_ethcat6),\n",
    "        'e_quality_ethcat7': np.mean(e_quality_ethcat7),\n",
    "\n",
    "        'avg_ClassI_HLA_ethcat1': np.mean(HLA_classI_ethcat[1]),\n",
    "        'avg_ClassI_HLA_ethcat2': np.mean(HLA_classI_ethcat[2]),\n",
    "        'avg_ClassI_HLA_ethcat4': np.mean(HLA_classI_ethcat[4]),\n",
    "        'avg_ClassI_HLA_ethcat5': np.mean(HLA_classI_ethcat[5]),\n",
    "        'avg_ClassI_HLA_ethcat6': np.mean(HLA_classI_ethcat[6]),\n",
    "        'avg_ClassI_HLA_ethcat7': np.mean(HLA_classI_ethcat[7]),\n",
    "        'HLA_ClassI_total': np.mean(HLA_classI_ethcat[1] + HLA_classI_ethcat[2] + HLA_classI_ethcat[4] +\n",
    "                                    HLA_classI_ethcat[5] + HLA_classI_ethcat[6] + HLA_classI_ethcat[7]),\n",
    "\n",
    "        'avg_DR_HLA_ethcat1': np.mean(HLA_DR_ethcat[1]),\n",
    "        'avg_DR_HLA_ethcat2': np.mean(HLA_DR_ethcat[2]),\n",
    "        'avg_DR_HLA_ethcat4': np.mean(HLA_DR_ethcat[4]),\n",
    "        'avg_DR_HLA_ethcat5': np.mean(HLA_DR_ethcat[5]),\n",
    "        'avg_DR_HLA_ethcat6': np.mean(HLA_DR_ethcat[6]),\n",
    "        'avg_DR_HLA_ethcat7': np.mean(HLA_DR_ethcat[7]),\n",
    "        'HLA_DR_total': np.mean(HLA_DR_ethcat[1] + HLA_DR_ethcat[2] + HLA_DR_ethcat[4] +\n",
    "                                 HLA_DR_ethcat[5] + HLA_DR_ethcat[6] + HLA_DR_ethcat[7]),\n",
    "\n",
    "        'avg_DQ_HLA_ethcat1': np.mean(HLA_DQ_ethcat[1]),\n",
    "        'avg_DQ_HLA_ethcat2': np.mean(HLA_DQ_ethcat[2]),\n",
    "        'avg_DQ_HLA_ethcat4': np.mean(HLA_DQ_ethcat[4]),\n",
    "        'avg_DQ_HLA_ethcat5': np.mean(HLA_DQ_ethcat[5]),\n",
    "        'avg_DQ_HLA_ethcat6': np.mean(HLA_DQ_ethcat[6]),\n",
    "        'avg_DQ_HLA_ethcat7': np.mean(HLA_DQ_ethcat[7]),\n",
    "        'HLA_DQ_total': np.mean(HLA_DQ_ethcat[1] + HLA_DQ_ethcat[2] + HLA_DQ_ethcat[4] +\n",
    "                                 HLA_DQ_ethcat[5] + HLA_DQ_ethcat[6] + HLA_DQ_ethcat[7]),\n",
    "\n",
    "        'F_per_ethcat': F_per_ethcat,\n",
    "        'L_per_ethcat': L_per_ethcat,\n",
    "        'F_total': F_total,\n",
    "        'lr_quality_total': np.mean(lr_quality_ethcat1 + lr_quality_ethcat2 + lr_quality_ethcat4 +\n",
    "                                    lr_quality_ethcat5 + lr_quality_ethcat6 + lr_quality_ethcat7),\n",
    "        'hr_quality_total': np.mean(hr_quality_ethcat1 + hr_quality_ethcat2 + hr_quality_ethcat4 +\n",
    "                                    hr_quality_ethcat5 + hr_quality_ethcat6 + hr_quality_ethcat7),\n",
    "        'e_quality_total': np.mean(e_quality_ethcat1 + e_quality_ethcat2 + e_quality_ethcat4 +\n",
    "                                   e_quality_ethcat5 + e_quality_ethcat6 + e_quality_ethcat7),\n",
    "        'Waiting_time_mean': pd.concat([\n",
    "            df_ethnicity[df_ethnicity['ethnicity'] == e]['waiting time (months)'] for e in [1,2,4,5,6,7]\n",
    "        ]).mean() if not df_ethnicity.empty else np.nan\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(m1, m2, m4, m5, base_seed=12345):\n",
    "    \n",
    "    multipliers_ethnicity = {\n",
    "    1: m1,\n",
    "    2: m2,\n",
    "    4: m4,\n",
    "    5: m5,\n",
    "    6: 1.0,\n",
    "    7: 1.0\n",
    "}\n",
    "\n",
    "    simulations_results = []\n",
    "    for i in range(100):\n",
    "        #print(f\"Runing simulation {i + 1} of 100\")\n",
    "        seed_i = base_seed + i\n",
    "\n",
    "        results = run_simulation(\n",
    "            total_time=10*12, \n",
    "            arrival_rate=(990/(10*12)), \n",
    "            departure_rate=((990/(10*12))*0.29), \n",
    "            match_run=3,\n",
    "            pairs=pairs, \n",
    "            compatibility=compatibility, \n",
    "            hla_lr = hla_lr,\n",
    "            hla_hr=hla_hr,\n",
    "            hla_eplet= hla_eplet,\n",
    "            multipliers_ethnicity= multipliers_ethnicity,\n",
    "            seed=seed_i  \n",
    "        )\n",
    "    \n",
    "        simulations_results.append({\n",
    "            'simulation': i + 1,\n",
    "            'cycles': results['historial_cycles'],\n",
    "            'total_cycles': len(results['historial_cycles']),\n",
    "            'total_departures': len(results['historial_departures']),\n",
    "            'total_entries': results['entries_nodes'],\n",
    "            'arrivals_by_ethcat': results['arrivals_by_ethcat'],\n",
    "            'waiting_time_mean1':   results['waiting_time_mean1'] ,\n",
    "            'waiting_time_mean2':   results['waiting_time_mean2'],\n",
    "            'waiting_time_mean4':   results['waiting_time_mean4'],\n",
    "            'waiting_time_mean5':   results['waiting_time_mean5'],\n",
    "            'waiting_time_mean6':   results['waiting_time_mean6'],\n",
    "            'waiting_time_mean7':   results['waiting_time_mean7'],\n",
    "            'lr_quality_ethcat1': results['lr_quality_ethcat1'],\n",
    "            'lr_quality_ethcat2': results['lr_quality_ethcat2'],\n",
    "            'lr_quality_ethcat4': results['lr_quality_ethcat4'],\n",
    "            'lr_quality_ethcat5': results['lr_quality_ethcat5'],\n",
    "            'lr_quality_ethcat6': results['lr_quality_ethcat6'],\n",
    "            'lr_quality_ethcat7': results['lr_quality_ethcat7'],\n",
    "            'hr_quality_ethcat1': results['hr_quality_ethcat1'],\n",
    "            'hr_quality_ethcat2': results['hr_quality_ethcat2'],\n",
    "            'hr_quality_ethcat4': results['hr_quality_ethcat4'],\n",
    "            'hr_quality_ethcat5': results['hr_quality_ethcat5'],\n",
    "            'hr_quality_ethcat6': results['hr_quality_ethcat6'],\n",
    "            'hr_quality_ethcat7': results['hr_quality_ethcat7'],\n",
    "            'e_quality_ethcat1': results['e_quality_ethcat1'],\n",
    "            'e_quality_ethcat2': results['e_quality_ethcat2'],\n",
    "            'e_quality_ethcat4': results['e_quality_ethcat4'],\n",
    "            'e_quality_ethcat5': results['e_quality_ethcat5'],\n",
    "            'e_quality_ethcat6': results['e_quality_ethcat6'],\n",
    "            'e_quality_ethcat7': results['e_quality_ethcat7'],\n",
    "            'avg_ClassI_HLA_ethcat1': results['avg_ClassI_HLA_ethcat1'],\n",
    "            'avg_ClassI_HLA_ethcat2': results['avg_ClassI_HLA_ethcat2'],\n",
    "            'avg_ClassI_HLA_ethcat4': results['avg_ClassI_HLA_ethcat4'],\n",
    "            'avg_ClassI_HLA_ethcat5': results['avg_ClassI_HLA_ethcat5'],\n",
    "            'avg_ClassI_HLA_ethcat6': results['avg_ClassI_HLA_ethcat6'],\n",
    "            'avg_ClassI_HLA_ethcat7': results['avg_ClassI_HLA_ethcat7'],\n",
    "            'HLA_ClassI_total': results['HLA_ClassI_total'],\n",
    "\n",
    "            'avg_DR_HLA_ethcat1': results['avg_DR_HLA_ethcat1'],\n",
    "            'avg_DR_HLA_ethcat2': results['avg_DR_HLA_ethcat2'],\n",
    "            'avg_DR_HLA_ethcat4': results['avg_DR_HLA_ethcat4'],\n",
    "            'avg_DR_HLA_ethcat5': results['avg_DR_HLA_ethcat5'],\n",
    "            'avg_DR_HLA_ethcat6': results['avg_DR_HLA_ethcat6'],\n",
    "            'avg_DR_HLA_ethcat7': results['avg_DR_HLA_ethcat7'],\n",
    "            'HLA_DR_total': results['HLA_DR_total'],\n",
    "            \n",
    "\n",
    "            'avg_DQ_HLA_ethcat1': results['avg_DQ_HLA_ethcat1'],\n",
    "            'avg_DQ_HLA_ethcat2': results['avg_DQ_HLA_ethcat2'],\n",
    "            'avg_DQ_HLA_ethcat4': results['avg_DQ_HLA_ethcat4'],\n",
    "            'avg_DQ_HLA_ethcat5': results['avg_DQ_HLA_ethcat5'],\n",
    "            'avg_DQ_HLA_ethcat6': results['avg_DQ_HLA_ethcat6'],\n",
    "            'avg_DQ_HLA_ethcat7': results['avg_DQ_HLA_ethcat7'],\n",
    "            'HLA_DQ_total': results['HLA_DQ_total'],\n",
    "\n",
    "            'F_per_ethcat':   results['F_per_ethcat'],   \n",
    "            'L_per_ethcat':   results['L_per_ethcat'],   \n",
    "            'F_total': results['F_total'],\n",
    "            'lr_quality_total': results['lr_quality_total'],\n",
    "            'hr_quality_total': results['hr_quality_total'],\n",
    "            'e_quality_total': results['e_quality_total'],\n",
    "            'Waiting_time_mean': results['Waiting_time_mean']\n",
    "        })\n",
    "        \n",
    "        \n",
    "    df_results = pd.DataFrame(simulations_results)\n",
    "    z = 10 #HERE change the z. 10 for LR and HR, 138 for eplet.\n",
    "    F_P = np.mean(df_results['F_total'])\n",
    "    HLA_P = np.mean(df_results['lr_quality_total']) /z #HERE change the resolution\n",
    "    \n",
    "    results_ethnicity = []\n",
    "    \n",
    "\n",
    "    for index, row in df_results.iterrows():\n",
    "        nodes = set(nodo for ciclo in row['cycles'] for nodo in ciclo)\n",
    "        df_nodes = recipients[recipients['Nodo'].isin(nodes)]\n",
    "        count_ethnicity = df_nodes['ETHCAT'].value_counts().to_dict()\n",
    "        results_ethnicity .append({'simulation': row['simulation'], **count_ethnicity})\n",
    "\n",
    "    df_results_ethnicity  = pd.DataFrame(results_ethnicity ).fillna(0)\n",
    "    arrivals_by_ethcat = pd.DataFrame(df_results['arrivals_by_ethcat'].tolist())\n",
    "    arrivals_by_ethcat_mean = arrivals_by_ethcat.mean()\n",
    "    target_ethnicity = [1, 2, 4, 5, 6, 7]\n",
    "    m = sum(arrivals_by_ethcat_mean[e] for e in target_ethnicity) \n",
    "    target_ethnicity = [1, 2, 4, 5]\n",
    "    transplant_by_ethcat_mean = df_results_ethnicity.mean()\n",
    "    percentage_by_ethnicity = (transplant_by_ethcat_mean) / arrivals_by_ethcat_mean\n",
    "    quality = df_results[\n",
    "        ['lr_quality_ethcat1', 'lr_quality_ethcat2', 'lr_quality_ethcat4', 'lr_quality_ethcat5'] #HERE change the resolution\n",
    "    ].mean()\n",
    "    quality = quality / z\n",
    "\n",
    "    kpi_total = 0\n",
    "    rows = []\n",
    "\n",
    "    for e in target_ethnicity:\n",
    "        \n",
    "        s = arrivals_by_ethcat_mean[e]\n",
    "        F_s = percentage_by_ethnicity[e]\n",
    "        HLA_s = quality[f'lr_quality_ethcat{e}'] #HERE change the resolution\n",
    "        ######\n",
    "        #F_diff = (s / m)*(F_s - F_P)\n",
    "        #HLA_diff = (s / m)*((1/m)*(HLA_s - HLA_P))\n",
    "\n",
    "        F_diff = F_s - F_P\n",
    "        HLA_diff = (HLA_s - HLA_P)/m\n",
    "        #####\n",
    "\n",
    "        term = (s / m) * (abs(F_s - F_P) + (1/m)*abs(HLA_s - HLA_P))\n",
    "        #term = (s / m) * (abs(F_s - F_P) + abs(HLA_s - HLA_P))\n",
    "\n",
    "        kpi_total = kpi_total + term\n",
    "        print(f\"For ethcat {e} : s = {s}, m = {m}, F_s = {F_s}, F_P = {F_P}, HLA_s = {HLA_s}, HLA_P = {HLA_P} \")\n",
    "\n",
    "        rows.append({\n",
    "        \"ethcat\": e,\n",
    "        \"kpi_total\": term,      \n",
    "        \"F_diff\": F_diff,         \n",
    "        \"HLA_diff\": HLA_diff    \n",
    "    })\n",
    "\n",
    "    tabla_kpi = pd.DataFrame(rows).set_index(\"ethcat\")\n",
    "    print(\"KPI:\",kpi_total)\n",
    "    print(\"\\nResume KPI per ethcat:\")\n",
    "    print(tabla_kpi.to_string(float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "    return tabla_kpi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6736256677260126, F_P = 0.6634285047535221, HLA_s = 0.3641041316502652, HLA_P = 0.33755433994196854 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6695089679506027, F_P = 0.6634285047535221, HLA_s = 0.2959061205813396, HLA_P = 0.33755433994196854 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6514060589593805, F_P = 0.6634285047535221, HLA_s = 0.30440358790694383, HLA_P = 0.33755433994196854 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.5883203760621949, F_P = 0.6634285047535221, HLA_s = 0.2629453061872452, HLA_P = 0.33755433994196854 \n",
      "KPI: 0.013315714166781466\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.006184  0.010197  0.000027\n",
      "2        0.001065  0.006080 -0.000043\n",
      "4        0.001815 -0.012022 -0.000034\n",
      "5        0.004252 -0.075108 -0.000076\n"
     ]
    }
   ],
   "source": [
    "tabla = objective_function(1,1.003,1.003,1.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpi_total</th>\n",
       "      <th>F_diff</th>\n",
       "      <th>HLA_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethcat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016945</td>\n",
       "      <td>0.027995</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006334</td>\n",
       "      <td>-0.036389</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008173</td>\n",
       "      <td>-0.054276</td>\n",
       "      <td>-0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001737</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        kpi_total    F_diff  HLA_diff\n",
       "ethcat                               \n",
       "1        0.016945  0.027995  0.000020\n",
       "2        0.006334 -0.036389 -0.000037\n",
       "4        0.008173 -0.054276 -0.000021\n",
       "5        0.001737 -0.030649 -0.000057"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTION 1 SEARCH JUST WITH \"F\" DIFFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6987625938197309, F_P = 0.6709550906277216, HLA_s = 0.470233449273064, HLA_P = 0.45119669872974166 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6408115260217583, F_P = 0.6709550906277216, HLA_s = 0.41555242105152573, HLA_P = 0.45119669872974166 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.623013177557397, F_P = 0.6709550906277216, HLA_s = 0.43156936271385027, HLA_P = 0.45119669872974166 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6085698788645814, F_P = 0.6709550906277216, HLA_s = 0.3937720627235929, HLA_P = 0.45119669872974166 \n",
      "KPI: 0.03283010246464941\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.016831  0.027808  0.000019\n",
      "2        0.005248 -0.030144 -0.000036\n",
      "4        0.007220 -0.047942 -0.000020\n",
      "5        0.003531 -0.062385 -0.000059\n",
      "[init] KPI = 0.032830  m = {1: 1.0, 2: 1.0, 4: 1.0, 5: 1.0}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6984921225234972, F_P = 0.6704969919268298, HLA_s = 0.471072361249511, HLA_P = 0.4516210909782948 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6341076154072331, F_P = 0.6704969919268298, HLA_s = 0.4152636614562254, HLA_P = 0.4516210909782948 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6162206221980709, F_P = 0.6704969919268298, HLA_s = 0.4307727841537994, HLA_P = 0.4516210909782948 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6398481287289821, F_P = 0.6704969919268298, HLA_s = 0.3962602074464153, HLA_P = 0.4516210909782948 \n",
      "KPI: 0.03318874527888718\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.016945  0.027995  0.000020\n",
      "2        0.006334 -0.036389 -0.000037\n",
      "4        0.008173 -0.054276 -0.000021\n",
      "5        0.001737 -0.030649 -0.000057\n",
      "[iter 1] give step=0.001 to ethcat 5 | KPI 0.032830 → 0.033189 | m={1: 1.0, 2: 1.0, 4: 1.0, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6959226452092773, F_P = 0.6720582957132735, HLA_s = 0.4690218108749039, HLA_P = 0.45104714190506023 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6311673037341957, F_P = 0.6720582957132735, HLA_s = 0.41635253441442044, HLA_P = 0.45104714190506023 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6413530770275778, F_P = 0.6720582957132735, HLA_s = 0.4348952464803788, HLA_P = 0.45104714190506023 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6393057313324896, F_P = 0.6720582957132735, HLA_s = 0.39639469503166885, HLA_P = 0.45104714190506023 \n",
      "KPI: 0.028041739033155648\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.014446  0.023864  0.000018\n",
      "2        0.007116 -0.040891 -0.000035\n",
      "4        0.004625 -0.030705 -0.000017\n",
      "5        0.001855 -0.032753 -0.000056\n",
      "[iter 2] give step=0.001 to ethcat 4 | KPI 0.033189 → 0.028042 | m={1: 1.0, 2: 1.0, 4: 1.001, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.690918926228954, F_P = 0.6711317036499644, HLA_s = 0.4692433118921729, HLA_P = 0.45098081033283466 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6502205233754778, F_P = 0.6711317036499644, HLA_s = 0.41836694910374683, HLA_P = 0.45098081033283466 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6384322782230675, F_P = 0.6711317036499644, HLA_s = 0.43348846350900594, HLA_P = 0.45098081033283466 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6237570059663713, F_P = 0.6711317036499644, HLA_s = 0.3951137947557791, HLA_P = 0.45098081033283466 \n",
      "KPI: 0.023228892445413003\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.011980  0.019787  0.000019\n",
      "2        0.003642 -0.020911 -0.000033\n",
      "4        0.004925 -0.032699 -0.000018\n",
      "5        0.002682 -0.047375 -0.000057\n",
      "[iter 3] give step=0.001 to ethcat 2 | KPI 0.028042 → 0.023229 | m={1: 1.0, 2: 1.001, 4: 1.001, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6870139968895802, F_P = 0.6697179741053829, HLA_s = 0.468310488829678, HLA_P = 0.44992627667573937 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6485739488385769, F_P = 0.6697179741053829, HLA_s = 0.4182704275385108, HLA_P = 0.44992627667573937 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6349680749898112, F_P = 0.6697179741053829, HLA_s = 0.4322377429975659, HLA_P = 0.44992627667573937 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6526848671126378, F_P = 0.6697179741053829, HLA_s = 0.39326942206178034, HLA_P = 0.44992627667573937 \n",
      "KPI: 0.02035526103167204\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.010473  0.017296  0.000019\n",
      "2        0.003682 -0.021144 -0.000032\n",
      "4        0.005234 -0.034750 -0.000018\n",
      "5        0.000967 -0.017033 -0.000058\n",
      "[iter 4] give step=0.001 to ethcat 5 | KPI 0.023229 → 0.020355 | m={1: 1.0, 2: 1.001, 4: 1.001, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6840388126310095, F_P = 0.670137487399427, HLA_s = 0.4687274195256802, HLA_P = 0.45037097474014026 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6435754189944134, F_P = 0.670137487399427, HLA_s = 0.4176685214796991, HLA_P = 0.45037097474014026 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.657994837657927, F_P = 0.670137487399427, HLA_s = 0.43430638317422127, HLA_P = 0.45037097474014026 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6478032905442054, F_P = 0.670137487399427, HLA_s = 0.39384341175088966, HLA_P = 0.45037097474014026 \n",
      "KPI: 0.016140629684346403\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.008420  0.013901  0.000019\n",
      "2        0.004624 -0.026562 -0.000033\n",
      "4        0.001830 -0.012143 -0.000016\n",
      "5        0.001266 -0.022334 -0.000058\n",
      "[iter 5] give step=0.001 to ethcat 4 | KPI 0.020355 → 0.016141 | m={1: 1.0, 2: 1.001, 4: 1.0019999999999998, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6818919467171547, F_P = 0.6711430591539816, HLA_s = 0.46849514093527195, HLA_P = 0.4501967530146693 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6625698324022345, F_P = 0.6711430591539816, HLA_s = 0.4173865438980039, HLA_P = 0.4501967530146693 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6556174432821628, F_P = 0.6711430591539816, HLA_s = 0.43514161462817824, HLA_P = 0.4501967530146693 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6416561200506238, F_P = 0.6711430591539816, HLA_s = 0.3953340174611207, HLA_P = 0.4501967530146693 \n",
      "KPI: 0.012019544431221392\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.006513  0.010749  0.000019\n",
      "2        0.001496 -0.008573 -0.000034\n",
      "4        0.002339 -0.015526 -0.000015\n",
      "5        0.001671 -0.029487 -0.000056\n",
      "[iter 6] give step=0.001 to ethcat 2 | KPI 0.016141 → 0.012020 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0019999999999998, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6802184055717088, F_P = 0.6713076134693824, HLA_s = 0.4689692080094653, HLA_P = 0.44994870278926696 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6604528079976477, F_P = 0.6713076134693824, HLA_s = 0.4164625488316826, HLA_P = 0.44994870278926696 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6534438255671784, F_P = 0.6713076134693824, HLA_s = 0.43320035422307585, HLA_P = 0.44994870278926696 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6698607846682335, F_P = 0.6713076134693824, HLA_s = 0.3956216399392972, HLA_P = 0.44994870278926696 \n",
      "KPI: 0.010071450639108772\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.005402  0.008911  0.000019\n",
      "2        0.001893 -0.010855 -0.000034\n",
      "4        0.002692 -0.017864 -0.000017\n",
      "5        0.000085 -0.001447 -0.000056\n",
      "[iter 7] give step=0.001 to ethcat 5 | KPI 0.012020 → 0.010071 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0019999999999998, 5: 1.0029999999999997}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6761951450402327, F_P = 0.6711284924606062, HLA_s = 0.4687062038082742, HLA_P = 0.4492037799672759 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6610996765657159, F_P = 0.6711284924606062, HLA_s = 0.41730180441294945, HLA_P = 0.4492037799672759 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6691346284472219, F_P = 0.6711284924606062, HLA_s = 0.4308137701391477, HLA_P = 0.4492037799672759 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.670403182064726, F_P = 0.6711284924606062, HLA_s = 0.3920294967875558, HLA_P = 0.4492037799672759 \n",
      "KPI: 0.0051733904002039\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.003077  0.005067  0.000020\n",
      "2        0.001749 -0.010029 -0.000033\n",
      "4        0.000303 -0.001994 -0.000019\n",
      "5        0.000044 -0.000725 -0.000058\n",
      "[iter 8] give step=0.001 to ethcat 4 | KPI 0.010071 → 0.005173 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6733890053418082, F_P = 0.6722360588256889, HLA_s = 0.46843765992784947, HLA_P = 0.44922292830582033 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6802705086739195, F_P = 0.6722360588256889, HLA_s = 0.4175973771215492, HLA_P = 0.44922292830582033 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6657383507675588, F_P = 0.6722360588256889, HLA_s = 0.43218416169456725, HLA_P = 0.44922292830582033 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6685951907430844, F_P = 0.6722360588256889, HLA_s = 0.3936543695909146, HLA_P = 0.44922292830582033 \n",
      "KPI: 0.0033016970859660513\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.000709  0.001153  0.000020\n",
      "2        0.001403  0.008034 -0.000032\n",
      "4        0.000981 -0.006498 -0.000017\n",
      "5        0.000209 -0.003641 -0.000057\n",
      "[iter 9] give step=0.001 to ethcat 2 | KPI 0.005173 → 0.003302 | m={1: 1.0, 2: 1.0029999999999997, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "[iter 10] Next step would revisit a previous state. Stop.\n",
      "Best m: {1: 1.0, 2: 1.0029999999999997, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "Best KPI: 0.0033016970859660513\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.000709  0.001153  0.000020\n",
      "2        0.001403  0.008034 -0.000032\n",
      "4        0.000981 -0.006498 -0.000017\n",
      "5        0.000209 -0.003641 -0.000057\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _kpi_total_from_table(tabla: pd.DataFrame) -> float:\n",
    "    #Sum of per-ethnicity KPI. \n",
    "    if 'kpi_total' not in tabla.columns:\n",
    "        raise ValueError(\"The table must have a 'kpi_total' column.\")\n",
    "    return float(tabla['kpi_total'].sum())\n",
    "\n",
    "def _get_F_col(tabla: pd.DataFrame) -> str:\n",
    "    #Return F-diff column \n",
    "    if 'F_diff' in tabla.columns:\n",
    "        return 'F_diff'\n",
    "    if 'F_s - F_P' in tabla.columns:\n",
    "        return 'F_s - F_P'\n",
    "    raise ValueError(\"The table must have an F column: 'F_diff' or 'F_s - F_P'.\")\n",
    "\n",
    "def _state_key(m: dict, round_decimals: int = 6):\n",
    "    #key for the multiplier state (rounded to avoid float noise)\n",
    "    return tuple(round(m[e], round_decimals) for e in (1,2,4,5))\n",
    "\n",
    "def _eval_state(m: dict, base_seed: int, cache: dict, state_round: int):\n",
    "    #Evaluate objective_function\n",
    "    key = _state_key(m, state_round)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    tabla = objective_function(m[1], m[2], m[4], m[5], base_seed=base_seed)\n",
    "    kpi = _kpi_total_from_table(tabla)\n",
    "    cache[key] = (tabla, kpi)\n",
    "    return tabla, kpi\n",
    "\n",
    "# algorithm\n",
    "def single_push_search(step=0.001, max_iters=200, f_zero_tol=1e-12, state_round=6, base_seed=12345, verbose=True):\n",
    "    \"\"\"\n",
    "     - Pick ethnicity with largest |F_diff|.\n",
    "      - If F_diff > 0 → decrease its multiplier by 'step'; if < 0 → increase it.\n",
    "      - Stop if the next state was already visited.\n",
    "      - Return the best state (lowest KPI) seen.\n",
    "    \"\"\"\n",
    "    # Initial multipliers\n",
    "    m = {1:1.0, 2:1.0, 4:1.0, 5:1.0}\n",
    "\n",
    "    cache = {}\n",
    "    tabla, kpi = _eval_state(m, base_seed, cache, state_round)\n",
    "    F_col = _get_F_col(tabla)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[init] KPI = {kpi:.6f}  m = {m}\")\n",
    "\n",
    "    history = [(0, m.copy(), kpi)]\n",
    "    seen = { _state_key(m, state_round) }\n",
    "\n",
    "    best_m, best_kpi, best_table = m.copy(), kpi, tabla.copy()\n",
    "\n",
    "    for it in range(1, max_iters+1):\n",
    "        # Select ethnicity with the largest absolute F deviation\n",
    "        F_series = tabla[F_col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if F_series.empty or F_series.abs().max() <= f_zero_tol:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] No useful signal in F (all ~0). Stop.\")\n",
    "            break\n",
    "\n",
    "        eth_star = int(F_series.abs().idxmax())\n",
    "        F_val = float(F_series.loc[eth_star])\n",
    "\n",
    "        # positive → take, negative → give\n",
    "        step_dir = -1.0 if F_val > 0.0 else (1.0 if F_val < 0.0 else 0.0)\n",
    "        if step_dir == 0.0:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] Top |F| is exactly 0. Stop.\")\n",
    "            break\n",
    "\n",
    "        proposed = m.copy()\n",
    "        proposed[eth_star] += step_dir * float(step)\n",
    "\n",
    "        # Stop if this state was already explored\n",
    "        key = _state_key(proposed, state_round)\n",
    "        if key in seen:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] Next step would revisit a previous state. Stop.\")\n",
    "            break\n",
    "\n",
    "        # Evaluate proposed state\n",
    "        new_tabla, new_kpi = _eval_state(proposed, base_seed, cache, state_round)\n",
    "\n",
    "        if verbose:\n",
    "            action = \"give\" if step_dir > 0 else \"take\"\n",
    "            print(f\"[iter {it}] {action} step={step:.3f} to ethcat {eth_star} \"\n",
    "                  f\"| KPI {kpi:.6f} → {new_kpi:.6f} | m={proposed}\")\n",
    "\n",
    "        m, tabla, kpi = proposed, new_tabla, new_kpi\n",
    "        F_col = _get_F_col(tabla)\n",
    "        seen.add(key)\n",
    "        history.append((it, m.copy(), kpi))\n",
    "\n",
    "        if new_kpi < best_kpi:\n",
    "            best_kpi = new_kpi\n",
    "            best_m = m.copy()\n",
    "            best_table = tabla.copy()\n",
    "\n",
    "    return {\n",
    "        \"best_multipliers\": best_m,\n",
    "        \"best_kpi\": best_kpi,\n",
    "        \"best_table\": best_table,\n",
    "        \"last_multipliers\": m,        \n",
    "        \"last_kpi\": kpi,\n",
    "        \"last_table\": tabla,\n",
    "        \"history\": history,           \n",
    "        \"visited_count\": len(seen),\n",
    "    }\n",
    "\n",
    "res = single_push_search(step=0.001, max_iters=200, base_seed=12345, f_zero_tol=1e-12, state_round=6, verbose=True)\n",
    "print(\"Best m:\", res[\"best_multipliers\"])\n",
    "print(\"Best KPI:\", res[\"best_kpi\"])\n",
    "print(res[\"best_table\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTION 2 SEARCH WITH \"F\" DIFFERENCE AND \"HLA\" DIFFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6987625938197309, F_P = 0.6709550906277216, HLA_s = 0.470233449273064, HLA_P = 0.45119669872974166 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6408115260217583, F_P = 0.6709550906277216, HLA_s = 0.41555242105152573, HLA_P = 0.45119669872974166 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.623013177557397, F_P = 0.6709550906277216, HLA_s = 0.43156936271385027, HLA_P = 0.45119669872974166 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6085698788645814, F_P = 0.6709550906277216, HLA_s = 0.3937720627235929, HLA_P = 0.45119669872974166 \n",
      "KPI: 0.03283010246464941\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.016831  0.027808  0.000019\n",
      "2        0.005248 -0.030144 -0.000036\n",
      "4        0.007220 -0.047942 -0.000020\n",
      "5        0.003531 -0.062385 -0.000059\n",
      "[init] KPI = 0.032830  m = {1: 1.0, 2: 1.0, 4: 1.0, 5: 1.0}  | base_seed=12345\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6984921225234972, F_P = 0.6704969919268298, HLA_s = 0.471072361249511, HLA_P = 0.4516210909782948 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6341076154072331, F_P = 0.6704969919268298, HLA_s = 0.4152636614562254, HLA_P = 0.4516210909782948 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6162206221980709, F_P = 0.6704969919268298, HLA_s = 0.4307727841537994, HLA_P = 0.4516210909782948 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6398481287289821, F_P = 0.6704969919268298, HLA_s = 0.3962602074464153, HLA_P = 0.4516210909782948 \n",
      "KPI: 0.03318874527888718\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.016945  0.027995  0.000020\n",
      "2        0.006334 -0.036389 -0.000037\n",
      "4        0.008173 -0.054276 -0.000021\n",
      "5        0.001737 -0.030649 -0.000057\n",
      "[iter 1] give step=0.001 to ethcat 5 (signal=F, diff=-0.062385) | KPI 0.032830 → 0.033189 | m={1: 1.0, 2: 1.0, 4: 1.0, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6959226452092773, F_P = 0.6720582957132735, HLA_s = 0.4690218108749039, HLA_P = 0.45104714190506023 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6311673037341957, F_P = 0.6720582957132735, HLA_s = 0.41635253441442044, HLA_P = 0.45104714190506023 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6413530770275778, F_P = 0.6720582957132735, HLA_s = 0.4348952464803788, HLA_P = 0.45104714190506023 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6393057313324896, F_P = 0.6720582957132735, HLA_s = 0.39639469503166885, HLA_P = 0.45104714190506023 \n",
      "KPI: 0.028041739033155648\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.014446  0.023864  0.000018\n",
      "2        0.007116 -0.040891 -0.000035\n",
      "4        0.004625 -0.030705 -0.000017\n",
      "5        0.001855 -0.032753 -0.000056\n",
      "[iter 2] give step=0.001 to ethcat 4 (signal=F, diff=-0.054276) | KPI 0.033189 → 0.028042 | m={1: 1.0, 2: 1.0, 4: 1.001, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.690918926228954, F_P = 0.6711317036499644, HLA_s = 0.4692433118921729, HLA_P = 0.45098081033283466 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6502205233754778, F_P = 0.6711317036499644, HLA_s = 0.41836694910374683, HLA_P = 0.45098081033283466 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6384322782230675, F_P = 0.6711317036499644, HLA_s = 0.43348846350900594, HLA_P = 0.45098081033283466 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6237570059663713, F_P = 0.6711317036499644, HLA_s = 0.3951137947557791, HLA_P = 0.45098081033283466 \n",
      "KPI: 0.023228892445413003\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.011980  0.019787  0.000019\n",
      "2        0.003642 -0.020911 -0.000033\n",
      "4        0.004925 -0.032699 -0.000018\n",
      "5        0.002682 -0.047375 -0.000057\n",
      "[iter 3] give step=0.001 to ethcat 2 (signal=F, diff=-0.040891) | KPI 0.028042 → 0.023229 | m={1: 1.0, 2: 1.001, 4: 1.001, 5: 1.001}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6870139968895802, F_P = 0.6697179741053829, HLA_s = 0.468310488829678, HLA_P = 0.44992627667573937 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6485739488385769, F_P = 0.6697179741053829, HLA_s = 0.4182704275385108, HLA_P = 0.44992627667573937 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6349680749898112, F_P = 0.6697179741053829, HLA_s = 0.4322377429975659, HLA_P = 0.44992627667573937 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6526848671126378, F_P = 0.6697179741053829, HLA_s = 0.39326942206178034, HLA_P = 0.44992627667573937 \n",
      "KPI: 0.02035526103167204\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.010473  0.017296  0.000019\n",
      "2        0.003682 -0.021144 -0.000032\n",
      "4        0.005234 -0.034750 -0.000018\n",
      "5        0.000967 -0.017033 -0.000058\n",
      "[iter 4] give step=0.001 to ethcat 5 (signal=F, diff=-0.047375) | KPI 0.023229 → 0.020355 | m={1: 1.0, 2: 1.001, 4: 1.001, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6840388126310095, F_P = 0.670137487399427, HLA_s = 0.4687274195256802, HLA_P = 0.45037097474014026 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6435754189944134, F_P = 0.670137487399427, HLA_s = 0.4176685214796991, HLA_P = 0.45037097474014026 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.657994837657927, F_P = 0.670137487399427, HLA_s = 0.43430638317422127, HLA_P = 0.45037097474014026 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6478032905442054, F_P = 0.670137487399427, HLA_s = 0.39384341175088966, HLA_P = 0.45037097474014026 \n",
      "KPI: 0.016140629684346403\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.008420  0.013901  0.000019\n",
      "2        0.004624 -0.026562 -0.000033\n",
      "4        0.001830 -0.012143 -0.000016\n",
      "5        0.001266 -0.022334 -0.000058\n",
      "[iter 5] give step=0.001 to ethcat 4 (signal=F, diff=-0.034750) | KPI 0.020355 → 0.016141 | m={1: 1.0, 2: 1.001, 4: 1.0019999999999998, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6818919467171547, F_P = 0.6711430591539816, HLA_s = 0.46849514093527195, HLA_P = 0.4501967530146693 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6625698324022345, F_P = 0.6711430591539816, HLA_s = 0.4173865438980039, HLA_P = 0.4501967530146693 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6556174432821628, F_P = 0.6711430591539816, HLA_s = 0.43514161462817824, HLA_P = 0.4501967530146693 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6416561200506238, F_P = 0.6711430591539816, HLA_s = 0.3953340174611207, HLA_P = 0.4501967530146693 \n",
      "KPI: 0.012019544431221392\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.006513  0.010749  0.000019\n",
      "2        0.001496 -0.008573 -0.000034\n",
      "4        0.002339 -0.015526 -0.000015\n",
      "5        0.001671 -0.029487 -0.000056\n",
      "[iter 6] give step=0.001 to ethcat 2 (signal=F, diff=-0.026562) | KPI 0.016141 → 0.012020 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0019999999999998, 5: 1.0019999999999998}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6802184055717088, F_P = 0.6713076134693824, HLA_s = 0.4689692080094653, HLA_P = 0.44994870278926696 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6604528079976477, F_P = 0.6713076134693824, HLA_s = 0.4164625488316826, HLA_P = 0.44994870278926696 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6534438255671784, F_P = 0.6713076134693824, HLA_s = 0.43320035422307585, HLA_P = 0.44994870278926696 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6698607846682335, F_P = 0.6713076134693824, HLA_s = 0.3956216399392972, HLA_P = 0.44994870278926696 \n",
      "KPI: 0.010071450639108772\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.005402  0.008911  0.000019\n",
      "2        0.001893 -0.010855 -0.000034\n",
      "4        0.002692 -0.017864 -0.000017\n",
      "5        0.000085 -0.001447 -0.000056\n",
      "[iter 7] give step=0.001 to ethcat 5 (signal=F, diff=-0.029487) | KPI 0.012020 → 0.010071 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0019999999999998, 5: 1.0029999999999997}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6761951450402327, F_P = 0.6711284924606062, HLA_s = 0.4687062038082742, HLA_P = 0.4492037799672759 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6610996765657159, F_P = 0.6711284924606062, HLA_s = 0.41730180441294945, HLA_P = 0.4492037799672759 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6691346284472219, F_P = 0.6711284924606062, HLA_s = 0.4308137701391477, HLA_P = 0.4492037799672759 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.670403182064726, F_P = 0.6711284924606062, HLA_s = 0.3920294967875558, HLA_P = 0.4492037799672759 \n",
      "KPI: 0.0051733904002039\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.003077  0.005067  0.000020\n",
      "2        0.001749 -0.010029 -0.000033\n",
      "4        0.000303 -0.001994 -0.000019\n",
      "5        0.000044 -0.000725 -0.000058\n",
      "[iter 8] give step=0.001 to ethcat 4 (signal=F, diff=-0.017864) | KPI 0.010071 → 0.005173 | m={1: 1.0, 2: 1.0019999999999998, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "For ethcat 1 : s = 591.56, m = 978.0099999999999, F_s = 0.6733890053418082, F_P = 0.6722360588256889, HLA_s = 0.46843765992784947, HLA_P = 0.44922292830582033 \n",
      "For ethcat 2 : s = 170.05, m = 978.0099999999999, F_s = 0.6802705086739195, F_P = 0.6722360588256889, HLA_s = 0.4175973771215492, HLA_P = 0.44922292830582033 \n",
      "For ethcat 4 : s = 147.22, m = 978.0099999999999, F_s = 0.6657383507675588, F_P = 0.6722360588256889, HLA_s = 0.43218416169456725, HLA_P = 0.44922292830582033 \n",
      "For ethcat 5 : s = 55.31, m = 978.0099999999999, F_s = 0.6685951907430844, F_P = 0.6722360588256889, HLA_s = 0.3936543695909146, HLA_P = 0.44922292830582033 \n",
      "KPI: 0.0033016970859660513\n",
      "\n",
      "Resume KPI per ethcat:\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.000709  0.001153  0.000020\n",
      "2        0.001403  0.008034 -0.000032\n",
      "4        0.000981 -0.006498 -0.000017\n",
      "5        0.000209 -0.003641 -0.000057\n",
      "[iter 9] give step=0.001 to ethcat 2 (signal=F, diff=-0.010029) | KPI 0.005173 → 0.003302 | m={1: 1.0, 2: 1.0029999999999997, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "[iter 10] Next step would revisit a previous state. Stop.\n",
      "Best m: {1: 1.0, 2: 1.0029999999999997, 4: 1.0029999999999997, 5: 1.0029999999999997}\n",
      "Best KPI: 0.0033016970859660513\n",
      "        kpi_total    F_diff  HLA_diff\n",
      "ethcat                               \n",
      "1        0.000709  0.001153  0.000020\n",
      "2        0.001403  0.008034 -0.000032\n",
      "4        0.000981 -0.006498 -0.000017\n",
      "5        0.000209 -0.003641 -0.000057\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _kpi_total_from_table(tabla: pd.DataFrame) -> float:\n",
    "    #Sum of per-ethnicity KPI. \n",
    "    if 'kpi_total' not in tabla.columns:\n",
    "        raise ValueError(\"The table must have a 'kpi_total' column.\")\n",
    "    return float(tabla['kpi_total'].sum())\n",
    "\n",
    "def _get_F_col(tabla: pd.DataFrame) -> str:\n",
    "    #Resolve the F-difference column\n",
    "    if 'F_diff' in tabla.columns: return 'F_diff'\n",
    "    if 'F_s - F_P' in tabla.columns: return 'F_s - F_P'\n",
    "    raise ValueError(\"The table must have an F column: 'F_diff' or 'F_s - F_P'.\")\n",
    "\n",
    "def _get_H_col(tabla: pd.DataFrame) -> str:\n",
    "    # Resolve the HLA-difference column\n",
    "    if 'HLA_diff' in tabla.columns: return 'HLA_diff'\n",
    "    if 'HLA_s - HLA_P' in tabla.columns: return 'HLA_s - HLA_P'\n",
    "    raise ValueError(\"The table must have an HLA column: 'HLA_diff' or 'HLA_s - HLA_P'.\")\n",
    "\n",
    "def _state_key(m: dict, round_decimals: int = 6):\n",
    "    return tuple(round(m[e], round_decimals) for e in (1,2,4,5))\n",
    "\n",
    "def _eval_state(m: dict, base_seed: int, cache: dict, state_round: int):\n",
    "    key = _state_key(m, state_round)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    # objective_function \n",
    "    tabla = objective_function(m[1], m[2], m[4], m[5], base_seed=base_seed)\n",
    "    kpi = _kpi_total_from_table(tabla)\n",
    "    cache[key] = (tabla, kpi)\n",
    "    return tabla, kpi\n",
    "\n",
    "# algorithm\n",
    "def single_push_search_both(step=0.001, max_iters=200, zero_tol=1e-12,\n",
    "                            state_round=6, base_seed=12345, verbose=True):\n",
    "    \"\"\"\n",
    "      1) Read F and HLA diffs from the table.\n",
    "      2) Pick (ethnicity, signal) with largest |diff|.\n",
    "      3) If diff > 0 → TAKE 'step' from that ethnicity's multiplier.\n",
    "         If diff < 0 → GIVE 'step' to that ethnicity's multiplier.\n",
    "      4) Accept unless the next state was already visited (then stop).\n",
    "    Returns the best (lowest KPI) among all visited states.\n",
    "    \"\"\"\n",
    "    # Initial multipliers\n",
    "    m = {1:1.0, 2:1.0, 4:1.0, 5:1.0}\n",
    "    cache = {}\n",
    "\n",
    "    tabla, kpi = _eval_state(m, base_seed, cache, state_round)\n",
    "    F_col, H_col = _get_F_col(tabla), _get_H_col(tabla)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[init] KPI = {kpi:.6f}  m = {m}  | base_seed={base_seed}\")\n",
    "\n",
    "    history = [(0, m.copy(), kpi)]\n",
    "    seen = { _state_key(m, state_round) }\n",
    "    best_m, best_kpi, best_table = m.copy(), kpi, tabla.copy()\n",
    "\n",
    "    for it in range(1, max_iters+1):\n",
    "        F_series  = tabla[F_col].replace([np.inf, -np.inf], np.nan)\n",
    "        H_series  = tabla[H_col].replace([np.inf, -np.inf], np.nan)\n",
    "        long = pd.concat(\n",
    "            [F_series.rename('F'), H_series.rename('HLA')], axis=1\n",
    "        ).stack().dropna()          # Multiindex: (ethcat, signal)\n",
    "\n",
    "        if long.empty or long.abs().max() <= zero_tol:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] No useful signal in F/HLA (all ~0). Stop.\")\n",
    "            break\n",
    "\n",
    "        # # Pick the max absolute deviation (ethnicity, which signal)\n",
    "        idx_star = long.abs().idxmax()   # (ethcat, 'F' or 'HLA')\n",
    "        eth_star, sig_star = int(idx_star[0]), idx_star[1]\n",
    "        diff_val = float(long.loc[idx_star])\n",
    "\n",
    "        # Step direction\n",
    "        step_dir = -1.0 if diff_val > 0.0 else (1.0 if diff_val < 0.0 else 0.0)\n",
    "        if step_dir == 0.0:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] Top |diff| is exactly 0. Stop.\")\n",
    "            break\n",
    "\n",
    "        # Propose next multipliers\n",
    "        proposed = m.copy()\n",
    "        proposed[eth_star] += step_dir * float(step)\n",
    "\n",
    "        # Stop if we would revisit a previous state\n",
    "        key = _state_key(proposed, state_round)\n",
    "        if key in seen:\n",
    "            if verbose:\n",
    "                print(f\"[iter {it}] Next step would revisit a previous state. Stop.\")\n",
    "            break\n",
    "\n",
    "        # Evaluate proposed state\n",
    "        new_tabla, new_kpi = _eval_state(proposed, base_seed, cache, state_round)\n",
    "\n",
    "        if verbose:\n",
    "            action = \"give\" if step_dir > 0 else \"take\"\n",
    "            print(f\"[iter {it}] {action} step={step:.3f} to ethcat {eth_star} (signal={sig_star}, diff={diff_val:+.6f}) \"\n",
    "                  f\"| KPI {kpi:.6f} → {new_kpi:.6f} | m={proposed}\")\n",
    "\n",
    "        # Accept, record, and update best if improved\n",
    "        m, tabla, kpi = proposed, new_tabla, new_kpi\n",
    "        F_col, H_col = _get_F_col(tabla), _get_H_col(tabla)\n",
    "        seen.add(key)\n",
    "        history.append((it, m.copy(), kpi))\n",
    "\n",
    "        if new_kpi < best_kpi:\n",
    "            best_kpi = new_kpi\n",
    "            best_m = m.copy()\n",
    "            best_table = tabla.copy()\n",
    "\n",
    "    return {\n",
    "        \"best_multipliers\": best_m,\n",
    "        \"best_kpi\": best_kpi,\n",
    "        \"best_table\": best_table,\n",
    "        \"last_multipliers\": m,\n",
    "        \"last_kpi\": kpi,\n",
    "        \"last_table\": tabla,\n",
    "        \"history\": history,\n",
    "        \"visited_count\": len(seen),\n",
    "    }\n",
    "\n",
    "res = single_push_search_both(step=0.001, max_iters=200,\n",
    "                              zero_tol=1e-12, state_round=6,\n",
    "                              base_seed=12345, verbose=True)\n",
    "print(\"Best m:\", res[\"best_multipliers\"])\n",
    "print(\"Best KPI:\", res[\"best_kpi\"])\n",
    "print(res[\"best_table\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After of knowing m1, m2, m3 and m4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing simulation 1 of 100\n",
      "Runing simulation 2 of 100\n",
      "Runing simulation 3 of 100\n",
      "Runing simulation 4 of 100\n",
      "Runing simulation 5 of 100\n",
      "Runing simulation 6 of 100\n",
      "Runing simulation 7 of 100\n",
      "Runing simulation 8 of 100\n",
      "Runing simulation 9 of 100\n",
      "Runing simulation 10 of 100\n",
      "Runing simulation 11 of 100\n",
      "Runing simulation 12 of 100\n",
      "Runing simulation 13 of 100\n",
      "Runing simulation 14 of 100\n",
      "Runing simulation 15 of 100\n",
      "Runing simulation 16 of 100\n",
      "Runing simulation 17 of 100\n",
      "Runing simulation 18 of 100\n",
      "Runing simulation 19 of 100\n",
      "Runing simulation 20 of 100\n",
      "Runing simulation 21 of 100\n",
      "Runing simulation 22 of 100\n",
      "Runing simulation 23 of 100\n",
      "Runing simulation 24 of 100\n",
      "Runing simulation 25 of 100\n",
      "Runing simulation 26 of 100\n",
      "Runing simulation 27 of 100\n",
      "Runing simulation 28 of 100\n",
      "Runing simulation 29 of 100\n",
      "Runing simulation 30 of 100\n",
      "Runing simulation 31 of 100\n",
      "Runing simulation 32 of 100\n",
      "Runing simulation 33 of 100\n",
      "Runing simulation 34 of 100\n",
      "Runing simulation 35 of 100\n",
      "Runing simulation 36 of 100\n",
      "Runing simulation 37 of 100\n",
      "Runing simulation 38 of 100\n",
      "Runing simulation 39 of 100\n",
      "Runing simulation 40 of 100\n",
      "Runing simulation 41 of 100\n",
      "Runing simulation 42 of 100\n",
      "Runing simulation 43 of 100\n",
      "Runing simulation 44 of 100\n",
      "Runing simulation 45 of 100\n",
      "Runing simulation 46 of 100\n",
      "Runing simulation 47 of 100\n",
      "Runing simulation 48 of 100\n",
      "Runing simulation 49 of 100\n",
      "Runing simulation 50 of 100\n",
      "Runing simulation 51 of 100\n",
      "Runing simulation 52 of 100\n",
      "Runing simulation 53 of 100\n",
      "Runing simulation 54 of 100\n",
      "Runing simulation 55 of 100\n",
      "Runing simulation 56 of 100\n",
      "Runing simulation 57 of 100\n",
      "Runing simulation 58 of 100\n",
      "Runing simulation 59 of 100\n",
      "Runing simulation 60 of 100\n",
      "Runing simulation 61 of 100\n",
      "Runing simulation 62 of 100\n",
      "Runing simulation 63 of 100\n",
      "Runing simulation 64 of 100\n",
      "Runing simulation 65 of 100\n",
      "Runing simulation 66 of 100\n",
      "Runing simulation 67 of 100\n",
      "Runing simulation 68 of 100\n",
      "Runing simulation 69 of 100\n",
      "Runing simulation 70 of 100\n",
      "Runing simulation 71 of 100\n",
      "Runing simulation 72 of 100\n",
      "Runing simulation 73 of 100\n",
      "Runing simulation 74 of 100\n",
      "Runing simulation 75 of 100\n",
      "Runing simulation 76 of 100\n",
      "Runing simulation 77 of 100\n",
      "Runing simulation 78 of 100\n",
      "Runing simulation 79 of 100\n",
      "Runing simulation 80 of 100\n",
      "Runing simulation 81 of 100\n",
      "Runing simulation 82 of 100\n",
      "Runing simulation 83 of 100\n",
      "Runing simulation 84 of 100\n",
      "Runing simulation 85 of 100\n",
      "Runing simulation 86 of 100\n",
      "Runing simulation 87 of 100\n",
      "Runing simulation 88 of 100\n",
      "Runing simulation 89 of 100\n",
      "Runing simulation 90 of 100\n",
      "Runing simulation 91 of 100\n",
      "Runing simulation 92 of 100\n",
      "Runing simulation 93 of 100\n",
      "Runing simulation 94 of 100\n",
      "Runing simulation 95 of 100\n",
      "Runing simulation 96 of 100\n",
      "Runing simulation 97 of 100\n",
      "Runing simulation 98 of 100\n",
      "Runing simulation 99 of 100\n",
      "Runing simulation 100 of 100\n"
     ]
    }
   ],
   "source": [
    "#Insert the multipliers found \n",
    "\n",
    "multipliers_ethnicity = {\n",
    "    1: 1,\n",
    "    2: 1.003,\n",
    "    4: 1.004,\n",
    "    5: 1.006,\n",
    "    6: 1.0,\n",
    "    7: 1.0\n",
    "}\n",
    "\n",
    "simulations_results = []\n",
    "#base_seed=12345\n",
    "\n",
    "for i in range(100):\n",
    "    #seed_i = base_seed + i\n",
    "    print(f\"Runing simulation {i + 1} of 100\")\n",
    "    results = run_simulation(\n",
    "        total_time=10*12, \n",
    "        arrival_rate=(990/(10*12)), \n",
    "        departure_rate=((990/(10*12))*0.29), \n",
    "        match_run=3,\n",
    "        pairs=pairs, \n",
    "        compatibility=compatibility, \n",
    "        hla_lr = hla_lr,\n",
    "        hla_hr=hla_hr,\n",
    "        hla_eplet= hla_eplet,\n",
    "        multipliers_ethnicity= multipliers_ethnicity,\n",
    "        #seed=seed_i  \n",
    "    )\n",
    "   \n",
    "    simulations_results.append({\n",
    "        'simulacion': i + 1,\n",
    "        'cycles': results['historial_cycles'],\n",
    "        'total_cycles': len(results['historial_cycles']),\n",
    "        'total_departures': len(results['historial_departures']),\n",
    "        'total_entries': results['entries_nodes'],\n",
    "        'arrivals_by_ethcat': results['arrivals_by_ethcat'],\n",
    "        'waiting_time_mean1':   results['waiting_time_mean1'] ,\n",
    "        'waiting_time_mean2':   results['waiting_time_mean2'],\n",
    "        'waiting_time_mean4':   results['waiting_time_mean4'],\n",
    "        'waiting_time_mean5':   results['waiting_time_mean5'],\n",
    "        'waiting_time_mean6':   results['waiting_time_mean6'],\n",
    "        'waiting_time_mean7':   results['waiting_time_mean7'],\n",
    "        'lr_quality_ethcat1': results['lr_quality_ethcat1'],\n",
    "        'lr_quality_ethcat2': results['lr_quality_ethcat2'],\n",
    "        'lr_quality_ethcat4': results['lr_quality_ethcat4'],\n",
    "        'lr_quality_ethcat5': results['lr_quality_ethcat5'],\n",
    "        'lr_quality_ethcat6': results['lr_quality_ethcat6'],\n",
    "        'lr_quality_ethcat7': results['lr_quality_ethcat7'],\n",
    "        'hr_quality_ethcat1': results['hr_quality_ethcat1'],\n",
    "        'hr_quality_ethcat2': results['hr_quality_ethcat2'],\n",
    "        'hr_quality_ethcat4': results['hr_quality_ethcat4'],\n",
    "        'hr_quality_ethcat5': results['hr_quality_ethcat5'],\n",
    "        'hr_quality_ethcat6': results['hr_quality_ethcat6'],\n",
    "        'hr_quality_ethcat7': results['hr_quality_ethcat7'],\n",
    "        'e_quality_ethcat1': results['e_quality_ethcat1'],\n",
    "        'e_quality_ethcat2': results['e_quality_ethcat2'],\n",
    "        'e_quality_ethcat4': results['e_quality_ethcat4'],\n",
    "        'e_quality_ethcat5': results['e_quality_ethcat5'],\n",
    "        'e_quality_ethcat6': results['e_quality_ethcat6'],\n",
    "        'e_quality_ethcat7': results['e_quality_ethcat7'],\n",
    "        'avg_ClassI_HLA_ethcat1': results['avg_ClassI_HLA_ethcat1'],\n",
    "        'avg_ClassI_HLA_ethcat2': results['avg_ClassI_HLA_ethcat2'],\n",
    "        'avg_ClassI_HLA_ethcat4': results['avg_ClassI_HLA_ethcat4'],\n",
    "        'avg_ClassI_HLA_ethcat5': results['avg_ClassI_HLA_ethcat5'],\n",
    "        'avg_ClassI_HLA_ethcat6': results['avg_ClassI_HLA_ethcat6'],\n",
    "        'avg_ClassI_HLA_ethcat7': results['avg_ClassI_HLA_ethcat7'],\n",
    "        'HLA_ClassI_total': results['HLA_ClassI_total'],\n",
    "\n",
    "        'avg_DR_HLA_ethcat1': results['avg_DR_HLA_ethcat1'],\n",
    "        'avg_DR_HLA_ethcat2': results['avg_DR_HLA_ethcat2'],\n",
    "        'avg_DR_HLA_ethcat4': results['avg_DR_HLA_ethcat4'],\n",
    "        'avg_DR_HLA_ethcat5': results['avg_DR_HLA_ethcat5'],\n",
    "        'avg_DR_HLA_ethcat6': results['avg_DR_HLA_ethcat6'],\n",
    "        'avg_DR_HLA_ethcat7': results['avg_DR_HLA_ethcat7'],\n",
    "        'HLA_DR_total': results['HLA_DR_total'],\n",
    "        \n",
    "\n",
    "        'avg_DQ_HLA_ethcat1': results['avg_DQ_HLA_ethcat1'],\n",
    "        'avg_DQ_HLA_ethcat2': results['avg_DQ_HLA_ethcat2'],\n",
    "        'avg_DQ_HLA_ethcat4': results['avg_DQ_HLA_ethcat4'],\n",
    "        'avg_DQ_HLA_ethcat5': results['avg_DQ_HLA_ethcat5'],\n",
    "        'avg_DQ_HLA_ethcat6': results['avg_DQ_HLA_ethcat6'],\n",
    "        'avg_DQ_HLA_ethcat7': results['avg_DQ_HLA_ethcat7'],\n",
    "        'HLA_DQ_total': results['HLA_DQ_total'],\n",
    "\n",
    "        'F_per_ethcat':   results['F_per_ethcat'],   \n",
    "        'L_per_ethcat':   results['L_per_ethcat'],   \n",
    "        'F_total': results['F_total'],\n",
    "        'lr_quality_total': results['lr_quality_total'],\n",
    "        'hr_quality_total': results['hr_quality_total'],\n",
    "        'e_quality_total': results['e_quality_total'],\n",
    "        'Waiting_time_mean': results['Waiting_time_mean']\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(simulations_results)\n",
    "\n",
    "list_HLA_ClassI_total = df_results['HLA_ClassI_total'].tolist()\n",
    "\n",
    "\n",
    "list_HLA_DR_total = df_results['HLA_DR_total'].tolist()\n",
    "\n",
    "\n",
    "list_HLA_DQ_total = df_results['HLA_DQ_total'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "lists_ClassI = {\n",
    "    1: df_results['avg_ClassI_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_ClassI_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_ClassI_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_ClassI_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_ClassI_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_ClassI_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n",
    "lists_DR = {\n",
    "    1: df_results['avg_DR_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_DR_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_DR_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_DR_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_DR_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_DR_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n",
    "lists_DQ = {\n",
    "    1: df_results['avg_DQ_HLA_ethcat1'].dropna().tolist(),\n",
    "    2: df_results['avg_DQ_HLA_ethcat2'].dropna().tolist(),\n",
    "    4: df_results['avg_DQ_HLA_ethcat4'].dropna().tolist(),\n",
    "    5: df_results['avg_DQ_HLA_ethcat5'].dropna().tolist(),\n",
    "    6: df_results['avg_DQ_HLA_ethcat6'].dropna().tolist(),\n",
    "    7: df_results['avg_DQ_HLA_ethcat7'].dropna().tolist()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity(s)</th>\n",
       "      <th>Arrivals</th>\n",
       "      <th>Transplants</th>\n",
       "      <th>F(s) (Matched)</th>\n",
       "      <th>HLA(s) Antigen</th>\n",
       "      <th>HLA(s) Allele</th>\n",
       "      <th>HLA(s) Eplets</th>\n",
       "      <th>Waiting Time</th>\n",
       "      <th>L(s) (Left Unmatched)</th>\n",
       "      <th>1-F(s)-L(s) (Still in KEP)</th>\n",
       "      <th>HLA ClassI</th>\n",
       "      <th>HLA DR</th>\n",
       "      <th>HLA DQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>592.18</td>\n",
       "      <td>393.77</td>\n",
       "      <td>0.665 [0.661; 0.669]</td>\n",
       "      <td>4.612 [4.598; 4.627]</td>\n",
       "      <td>3.600 [3.586; 3.613]</td>\n",
       "      <td>92.703 [92.585; 92.821]</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>0.292 [0.288; 0.296]</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2.563 [2.550; 2.576]</td>\n",
       "      <td>0.909 [0.903; 0.914]</td>\n",
       "      <td>1.141 [1.136; 1.146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>170.27</td>\n",
       "      <td>112.47</td>\n",
       "      <td>0.660 [0.653; 0.668]</td>\n",
       "      <td>3.998 [3.973; 4.023]</td>\n",
       "      <td>2.923 [2.905; 2.941]</td>\n",
       "      <td>89.851 [89.641; 90.061]</td>\n",
       "      <td>3.504000</td>\n",
       "      <td>0.300 [0.293; 0.307]</td>\n",
       "      <td>0.039</td>\n",
       "      <td>2.103 [2.083; 2.122]</td>\n",
       "      <td>0.768 [0.757; 0.780]</td>\n",
       "      <td>1.127 [1.116; 1.138]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>147.23</td>\n",
       "      <td>98.45</td>\n",
       "      <td>0.669 [0.661; 0.676]</td>\n",
       "      <td>4.215 [4.186; 4.244]</td>\n",
       "      <td>3.035 [3.012; 3.058]</td>\n",
       "      <td>91.017 [90.749; 91.285]</td>\n",
       "      <td>3.473000</td>\n",
       "      <td>0.293 [0.286; 0.300]</td>\n",
       "      <td>0.038</td>\n",
       "      <td>2.313 [2.288; 2.339]</td>\n",
       "      <td>0.819 [0.807; 0.831]</td>\n",
       "      <td>1.083 [1.071; 1.094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>55.48</td>\n",
       "      <td>36.66</td>\n",
       "      <td>0.661 [0.649; 0.672]</td>\n",
       "      <td>3.829 [3.795; 3.864]</td>\n",
       "      <td>2.553 [2.530; 2.575]</td>\n",
       "      <td>84.494 [84.059; 84.930]</td>\n",
       "      <td>4.222000</td>\n",
       "      <td>0.303 [0.292; 0.315]</td>\n",
       "      <td>0.036</td>\n",
       "      <td>2.025 [1.991; 2.059]</td>\n",
       "      <td>0.711 [0.694; 0.729]</td>\n",
       "      <td>1.092 [1.075; 1.110]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7.91</td>\n",
       "      <td>6.21</td>\n",
       "      <td>0.785 [0.759; 0.811]</td>\n",
       "      <td>3.987 [3.877; 4.097]</td>\n",
       "      <td>3.122 [3.033; 3.210]</td>\n",
       "      <td>82.169 [80.994; 83.343]</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>0.191 [0.164; 0.217]</td>\n",
       "      <td>0.024</td>\n",
       "      <td>2.140 [2.050; 2.230]</td>\n",
       "      <td>0.789 [0.740; 0.838]</td>\n",
       "      <td>1.058 [1.010; 1.106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.289 [0.261; 0.316]</td>\n",
       "      <td>4.082 [3.878; 4.287]</td>\n",
       "      <td>2.901 [2.749; 3.052]</td>\n",
       "      <td>95.629 [93.865; 97.393]</td>\n",
       "      <td>8.215000</td>\n",
       "      <td>0.591 [0.559; 0.622]</td>\n",
       "      <td>0.121</td>\n",
       "      <td>2.030 [1.877; 2.184]</td>\n",
       "      <td>0.807 [0.717; 0.897]</td>\n",
       "      <td>1.245 [1.146; 1.343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Entire Population</td>\n",
       "      <td>979.01</td>\n",
       "      <td>649.28</td>\n",
       "      <td>0.663 [0.659; 0.667]</td>\n",
       "      <td>4.394 [4.383; 4.405]</td>\n",
       "      <td>3.331 [3.321; 3.342]</td>\n",
       "      <td>91.396 [91.302; 91.489]</td>\n",
       "      <td>3.472968</td>\n",
       "      <td>0.295 [0.291; 0.299]</td>\n",
       "      <td>0.042</td>\n",
       "      <td>2.410 [2.400; 2.419]</td>\n",
       "      <td>0.858 [0.854; 0.863]</td>\n",
       "      <td>1.126 [1.122; 1.131]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ethnicity(s)  Arrivals  Transplants        F(s) (Matched)  \\\n",
       "0                  1    592.18       393.77  0.665 [0.661; 0.669]   \n",
       "1                  2    170.27       112.47  0.660 [0.653; 0.668]   \n",
       "2                  4    147.23        98.45  0.669 [0.661; 0.676]   \n",
       "3                  5     55.48        36.66  0.661 [0.649; 0.672]   \n",
       "4                  6      7.91         6.21  0.785 [0.759; 0.811]   \n",
       "5                  7      5.94         1.72  0.289 [0.261; 0.316]   \n",
       "6  Entire Population    979.01       649.28  0.663 [0.659; 0.667]   \n",
       "\n",
       "         HLA(s) Antigen         HLA(s) Allele            HLA(s) Eplets  \\\n",
       "0  4.612 [4.598; 4.627]  3.600 [3.586; 3.613]  92.703 [92.585; 92.821]   \n",
       "1  3.998 [3.973; 4.023]  2.923 [2.905; 2.941]  89.851 [89.641; 90.061]   \n",
       "2  4.215 [4.186; 4.244]  3.035 [3.012; 3.058]  91.017 [90.749; 91.285]   \n",
       "3  3.829 [3.795; 3.864]  2.553 [2.530; 2.575]  84.494 [84.059; 84.930]   \n",
       "4  3.987 [3.877; 4.097]  3.122 [3.033; 3.210]  82.169 [80.994; 83.343]   \n",
       "5  4.082 [3.878; 4.287]  2.901 [2.749; 3.052]  95.629 [93.865; 97.393]   \n",
       "6  4.394 [4.383; 4.405]  3.331 [3.321; 3.342]  91.396 [91.302; 91.489]   \n",
       "\n",
       "   Waiting Time L(s) (Left Unmatched) 1-F(s)-L(s) (Still in KEP)  \\\n",
       "0      3.392000  0.292 [0.288; 0.296]                      0.043   \n",
       "1      3.504000  0.300 [0.293; 0.307]                      0.039   \n",
       "2      3.473000  0.293 [0.286; 0.300]                      0.038   \n",
       "3      4.222000  0.303 [0.292; 0.315]                      0.036   \n",
       "4      1.775000  0.191 [0.164; 0.217]                      0.024   \n",
       "5      8.215000  0.591 [0.559; 0.622]                      0.121   \n",
       "6      3.472968  0.295 [0.291; 0.299]                      0.042   \n",
       "\n",
       "             HLA ClassI                HLA DR                HLA DQ  \n",
       "0  2.563 [2.550; 2.576]  0.909 [0.903; 0.914]  1.141 [1.136; 1.146]  \n",
       "1  2.103 [2.083; 2.122]  0.768 [0.757; 0.780]  1.127 [1.116; 1.138]  \n",
       "2  2.313 [2.288; 2.339]  0.819 [0.807; 0.831]  1.083 [1.071; 1.094]  \n",
       "3  2.025 [1.991; 2.059]  0.711 [0.694; 0.729]  1.092 [1.075; 1.110]  \n",
       "4  2.140 [2.050; 2.230]  0.789 [0.740; 0.838]  1.058 [1.010; 1.106]  \n",
       "5  2.030 [1.877; 2.184]  0.807 [0.717; 0.897]  1.245 [1.146; 1.343]  \n",
       "6  2.410 [2.400; 2.419]  0.858 [0.854; 0.863]  1.126 [1.122; 1.131]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "ethnicity = [1, 2, 4, 5, 6, 7]\n",
    "n_sim = len(df_results)\n",
    "\n",
    "def media_ci(list):\n",
    "    m = np.mean(list)\n",
    "    s = np.std(list, ddof=1)\n",
    "    low, high = st.t.interval(0.95, len(list)-1, loc=m, scale=s/np.sqrt(len(list)))\n",
    "    return m, f\"{m:.3f} [{low:.3f}; {high:.3f}]\"\n",
    "\n",
    "rows = []\n",
    "# Reporting per ethnicity \n",
    "\n",
    "for e in ethnicity:\n",
    "    arrivals_e = df_results['arrivals_by_ethcat'].apply(lambda d: d.get(e, 0)).sum() / n_sim\n",
    "    transplants_e = df_results['cycles'].apply(\n",
    "        lambda cycles: sum(1 for c in cycles for n in c if recipients.loc[n, 'ETHCAT'] == e)\n",
    "    ).sum() / n_sim\n",
    "\n",
    "    F_vals = df_results['F_per_ethcat'].apply(lambda d: d[e])\n",
    "    _, txt_F = media_ci(F_vals)\n",
    "    std_F = np.std(F_vals, ddof=1)\n",
    "\n",
    "    lr_quality = df_results[f'lr_quality_ethcat{e}']\n",
    "    _, txt_antigen = media_ci(lr_quality)\n",
    "\n",
    "    hr_quality = df_results[f'hr_quality_ethcat{e}']\n",
    "    _, txt_allele = media_ci(hr_quality)\n",
    "\n",
    "    e_quality  = df_results[f'e_quality_ethcat{e}']\n",
    "    _, txt_eplet = media_ci(e_quality)\n",
    "\n",
    "    waiting = df_results[f'waiting_time_mean{e}'].mean()\n",
    "\n",
    "    L_vals = df_results['L_per_ethcat'].apply(lambda d: d[e])\n",
    "    _, txt_L = media_ci(L_vals)\n",
    "\n",
    "    f_mean = np.mean(F_vals)\n",
    "    l_mean = np.mean(L_vals)\n",
    "    still_in_kep = round(1 - f_mean - l_mean, 3)\n",
    "\n",
    "\n",
    "    list_classi = lists_ClassI[e]\n",
    "\n",
    "    _, txt_classi = media_ci(list_classi)\n",
    "\n",
    "    list_dr = lists_DR[e]\n",
    "    _, txt_dr = media_ci(list_dr)\n",
    "\n",
    "    list_dq = lists_DQ[e]\n",
    "    _, txt_dq = media_ci(list_dq)\n",
    "\n",
    "\n",
    "    rows.append({\n",
    "        'Ethnicity(s)': e,\n",
    "        'Arrivals': round(arrivals_e, 2),\n",
    "        'Transplants': round(transplants_e, 2),\n",
    "        'F(s) (Matched)': txt_F,\n",
    "        'HLA(s) Antigen': txt_antigen,\n",
    "        'HLA(s) Allele': txt_allele,\n",
    "        'HLA(s) Eplets': txt_eplet,\n",
    "        'Waiting Time': round(waiting, 3),\n",
    "        'L(s) (Left Unmatched)': txt_L,\n",
    "        '1-F(s)-L(s) (Still in KEP)': still_in_kep,\n",
    "        'HLA ClassI': txt_classi,\n",
    "        'HLA DR': txt_dr,\n",
    "        'HLA DQ': txt_dq,\n",
    "\n",
    "    })\n",
    "\n",
    "# Reporting the totals\n",
    "\n",
    "total_arrivals = sum(df_results['arrivals_by_ethcat'].apply(lambda d: sum(d.values()))) / n_sim\n",
    "total_transplants = df_results['cycles'].apply(lambda cycles: sum(len(c) for c in cycles)).sum() / n_sim\n",
    "F_total = total_transplants / total_arrivals\n",
    "\n",
    "\n",
    "F_s_total, txt_F_total = media_ci(df_results['F_total'])\n",
    "\n",
    "L_vals_flat = (df_results['total_departures'] / df_results['total_entries']).tolist()\n",
    "L_s_total, ic_L_total = media_ci(L_vals_flat)\n",
    "txt_L_total = ic_L_total\n",
    "\n",
    "_, txt_total_lr_quality = media_ci(df_results['lr_quality_total'])\n",
    "_,txt_total_hr_quality = media_ci(df_results['hr_quality_total'])\n",
    "_,txt_total_e_quality= media_ci(df_results['e_quality_total'])\n",
    "\n",
    "txt_waiting_time_mean = np.mean(df_results['Waiting_time_mean'])\n",
    "\n",
    "F_vals_flat = [df_results['F_per_ethcat'].iloc[i][e] for i in range(n_sim) for e in ethnicity]\n",
    "std_F_total = np.std(F_vals_flat, ddof=1)\n",
    "\n",
    "f_total_mean = F_total  \n",
    "total_outgoing = sum(\n",
    "    df_results['L_per_ethcat'].apply(lambda d: sum(d.values()))\n",
    ") / n_sim\n",
    "\n",
    "l_total_mean = total_outgoing / total_arrivals\n",
    "still_in_kep_total = round(1 - F_total - l_total_mean, 3)\n",
    "\n",
    "\n",
    "_, txt_classi_total = media_ci(list_HLA_ClassI_total)\n",
    "\n",
    "_, txt_dr_total = media_ci(list_HLA_DR_total )\n",
    "\n",
    "_, txt_dq_total = media_ci(list_HLA_DQ_total )\n",
    "\n",
    "rows.append({\n",
    "    'Ethnicity(s)': 'Entire Population',\n",
    "    'Arrivals': round(total_arrivals, 2),\n",
    "    'Transplants': round(total_transplants, 2),\n",
    "    'F(s) (Matched)': txt_F_total,\n",
    "    'HLA(s) Antigen': txt_total_lr_quality,\n",
    "    'HLA(s) Allele': txt_total_hr_quality,\n",
    "    'HLA(s) Eplets': txt_total_e_quality,\n",
    "    'Waiting Time': txt_waiting_time_mean,\n",
    "    'L(s) (Left Unmatched)': txt_L_total,\n",
    "    '1-F(s)-L(s) (Still in KEP)': f\"{(1 - L_s_total - F_s_total):.3f}\",\n",
    "    'HLA ClassI': txt_classi_total,\n",
    "    'HLA DR': txt_dr_total,\n",
    "    'HLA DQ': txt_dq_total\n",
    "})\n",
    "\n",
    "df_final_table = pd.DataFrame(rows)\n",
    "display(df_final_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
